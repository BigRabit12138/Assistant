19:36:38,691 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
19:36:38,714 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
19:36:38,719 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
19:36:38,769 assistant.memory.graphrag.index.run INFO Running pipeline.
19:36:38,769 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
19:36:38,770 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
19:36:38,770 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
19:36:38,771 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
19:36:38,771 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
19:36:38,778 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
19:36:38,785 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
19:36:38,785 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
19:39:20,89 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
19:39:20,91 assistant.memory.graphrag.index.run INFO dependencies for create_base_text_units: [].
19:39:36,686 datashaper.workflow.workflow INFO executing verb orderby
19:41:25,72 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
19:41:25,94 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
19:41:25,96 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
19:41:25,101 assistant.memory.graphrag.index.run INFO Running pipeline.
19:41:25,101 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
19:41:25,102 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
19:41:25,102 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
19:41:25,103 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
19:41:25,103 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
19:41:25,109 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
19:41:25,114 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
19:41:25,114 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
19:41:48,97 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
19:41:48,98 assistant.memory.graphrag.index.run INFO dependencies for create_base_text_units: [].
19:44:25,772 datashaper.workflow.workflow INFO executing verb orderby
19:51:04,875 datashaper.workflow.workflow INFO executing verb zip
20:47:13,312 datashaper.workflow.workflow INFO executing verb aggregate_override
21:04:48,746 datashaper.workflow.workflow INFO executing verb chunk
21:10:00,776 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
21:10:00,798 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:10:00,800 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
21:10:00,805 assistant.memory.graphrag.index.run INFO Running pipeline.
21:10:00,805 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:10:00,805 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
21:10:00,805 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
21:10:00,806 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:10:00,807 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:10:00,812 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
21:10:00,817 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:10:00,817 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
21:10:10,412 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
21:10:10,414 assistant.memory.graphrag.index.run INFO dependencies for create_base_text_units: [].
21:10:13,202 datashaper.workflow.workflow INFO executing verb orderby
21:10:15,598 datashaper.workflow.workflow INFO executing verb zip
21:10:38,446 datashaper.workflow.workflow INFO executing verb aggregate_override
21:10:44,411 datashaper.workflow.workflow INFO executing verb chunk
19:54:40,353 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
19:54:40,375 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
19:54:40,380 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
19:54:40,432 assistant.memory.graphrag.index.run INFO Running pipeline.
19:54:40,432 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
19:54:40,433 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
19:54:40,433 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
19:54:40,434 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
19:54:40,434 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
19:54:40,441 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
19:54:40,446 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
19:54:40,446 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
19:55:21,466 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
19:55:21,467 assistant.memory.graphrag.index.run INFO dependencies for create_base_text_units: [].
19:55:26,940 datashaper.workflow.workflow INFO executing verb orderby
19:55:37,175 datashaper.workflow.workflow INFO executing verb zip
19:55:37,181 datashaper.workflow.workflow INFO executing verb aggregate_override
19:55:37,200 datashaper.workflow.workflow INFO executing verb chunk
20:43:06,955 datashaper.workflow.workflow INFO executing verb select
20:43:50,775 datashaper.workflow.workflow INFO executing verb unroll
20:49:10,951 datashaper.workflow.workflow INFO executing verb rename
20:49:54,461 datashaper.workflow.workflow INFO executing verb genid
20:56:52,487 datashaper.workflow.workflow INFO executing verb unzip
21:10:17,104 datashaper.workflow.workflow INFO executing verb copy
21:13:54,496 datashaper.workflow.workflow INFO executing verb filter
21:42:40,796 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
21:44:51,174 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
21:45:16,322 assistant.memory.graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
21:45:16,328 assistant.memory.graphrag.index.run INFO read table form storage: create_base_text_units.parquet.
19:45:11,950 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
19:45:11,972 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
19:45:11,974 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
19:45:12,26 assistant.memory.graphrag.index.run INFO Running pipeline.
19:45:12,27 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
19:45:12,27 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
19:45:12,27 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
19:45:12,29 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
19:45:12,29 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
19:45:12,38 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
19:45:12,44 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
19:45:12,44 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
19:46:32,816 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
19:46:53,135 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
19:47:19,15 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
19:47:34,799 assistant.memory.graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
19:47:34,800 assistant.memory.graphrag.index.run INFO read table form storage: create_base_text_units.parquet.
19:48:17,483 datashaper.workflow.workflow INFO executing verb entity_extract
20:20:34,858 assistant.memory.graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:20:34,898 assistant.memory.graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:20:34,898 assistant.memory.graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
21:23:15,733 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
21:27:22,664 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries             took 171.9439999999995. input_tokens=2020, output_tokens=117.
21:28:36,45 assistant.memory.graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input_': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\nFormat each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in English as a single list of all the entities and relationships identified in step 1 and step 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n######################\n-Examples-\n######################\nExample 1:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor\'s authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan\'s shared commitment to discovery was an unspoken rebellion against Cruz\'s narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. "If this tech can be understood ..." Taylor said, their voice quieter, "It could change the game for us. For all of us."\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor\'s, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n######################\nOutput:\n("entity"<|>"Alex"<|>"person"<|>"Alex is a character who experiences frustration and is observant of the dynamics among other characters.")##\n("entity"<|>"Taylor"<|>"person"<|>"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.")##\n("entity"<|>"Jordan"<|>"person"<|>"Jordan shares a commitment to discovery and  has a significant interaction with Taylor regarding a device.")##\n("entity"<|>"Cruz"<|>"person"<|>"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.")##\n("entity"<|>"The Device"<|>"technology"<|>"The Device is central to the story, with potential game-changing implications, and revered by Taylor.")##\n("relationship"<|>"Alex"<|>"Taylor"<|>"Alex is affected by Taylor\'s authoritarian certainty and observes changes in Taylor\'s attitude towards the device."<|>7)##\n("relationship"<|>"Alex"<|>"Jordan"<|>"Alex and Jordan share a commitment to discovery, which contrasts with Cruz\'s vision."<|>6)##\n("relationship"<|>"Taylor"<|>"Jordan"<|>"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce."<|>8)##\n("relationship"<|>"Jordan"<|>"Cruz"<|>"Jordan\'s commitment to discovery is in rebellion against Cruz\'s vision of control and order."<|>5)##\n("relationship"<|>"Taylor"<|>"The Device"<|>"Taylor shows reverence towards the device, indicating its importance and potential impact."<|>9)<|COMPLETE|>\n################################\nExample 2:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nThey were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols-it demanded a new perspective, a new resolve.\n\nTension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity\'s place in the cosmos or condemn them to ignorance and potential peril.\n\nTheir connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer\'s latter instincts gained precedence- the team\'s mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\n######################\nOutput:\n("entity"<|>"Washington"<|>"location"<|>"Washington is a location where communications are being received, indicating its importance in the decision-making process.")##\n("entity"<|>"Operation: Dulce"<|>"mission"<|>"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.")##\n("entity"<|>"The team"<|>"organization"<|>"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.")##\n("relationship"<|>"The team"<|>"Washington"<|>"The team receives communications from Washington, which influences their decision-making process."<|>7)##\n("relationship"<|>"The team"<|>"Operation: Dulce"<|>"The team is directly involved in operation: Dulce, executing its evolved objectives and activities."<|>9)<|COMPLETE|>\n##############################\nExample 3:\n\nEntity_types: [person, role, technology, organization, event, location, concept]\nText:\nTheir voice slicing through the buzz of activity. "Control may be an illusion when facing an intelligence that literally writes its own rules," they stated stoically, casting a watchful eye over the flurry of data.\n\n"It\'s like it\'s learning to communicate," offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. "This gives talking to strangers\' a whole new meaning."\n\nAlex surveyed his team-each face a study in concentration, determination, and not a small measure of trepidation. "This might well be our first contact," he acknowledged, "And we need to be ready for whatever answers back." \n\nTogether, they stood on the edge of the unknown, forging humanity\'s response to a message from the heavens. The ensuing silence was palpable-a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\n\nThe encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\n######################\nOutput:\n("entity"<|>"Sam Rivera"<|>"person"<|>"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.")##\n("entity"<|>"Alex"<|>"person"<|>"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.")##\n("entity"<|>"Control"<|>"concept"<|>"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.")##\n("entity"<|>"Intelligence"<|>"concept"<|>"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.")##\n("entity"<|>"First Contact"<|>"event"<|>"First Contact is the potential initial communication between humanity and an unknown intelligence.")##\n("entity"<|>"Humanity\'s Response"<|>"event"<|>"Humanity\'s Response is the collective action taken by Alex\'s team in response to a message from an unknown intelligence.")##\n("relationship"<|>"Sam Rivera"<|>"Intelligence"<|>"Sam Rivera is directly involved in the process of learning to communication with the unknown intelligence."<|>9)##\n("relationship"<|>"Alex"<|>"First Contact"<|>"Alex leads the team that might be making the First Contact with the unknown intelligence."<|>10)##\n("relationship"<|>"Alex"<|>"Humanity\'s Response"<|>"Alex and hist team are the key figures in Humanity\'s Response to the unknown intelligence."<|>8)##\n("relationship"<|>"Control"<|>"Intelligence"<|>"The concept of Control is challenged by the Intelligence that writes its own rules."<|>7)<|COMPLETE|>\n#############################\n-Rea Data-\n###################\nEntity_types: organization,person,geo,event\nText:  his heavy jaw and iron-filing hair radiating sullenness. Mousy chignon turning to string, Mum abandoned her fried rice and fled the table. My brother Thomas faked obliviousness. My sister Miranda whimpered. We watched Mum, fragile in a tulip-print shift, flit across scorching sand and encounter the boxs weaver, a shrewd-faced Malay matriarch who discerned her distress.\n\nLucy twirled towards a red lacquer basket embellished with gilt.\n\nThat was for carrying wedding gifts in the old days, I explained.\n\nIn the shop, Dads accusations of stinginess confronted Mums anxiety. The Chinese shop assistant looked perturbed by Dads lack of decorum.\n\nLets hope the original couple who received it had better luck than us! Lets hope Mrs Khoo or whatever her name was, wasnt as stultifying as you, Dad told Mum.\n\nPeople forget that they hold their children hostage.\n\nLucy pointed to a Dutch ceiling lamp of wrought iron. Can I stand on the chair and dust that?\n\nI didnt want to be Boring Auntie Who Always Says No, so I held her legs and supervised her flourishing with a feather duster. The lamp swung wildly.\n\nHelena, youve got to see this! Its a bargain\n\nDarling, we cant afford it!\n\n**\n\nYoure so bone-achingly pedestrian!\n\nIf Mr Ramasamy throws\n###################\nOutput:'}.
21:43:50,348 assistant.memory.graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input_': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\nFormat each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in English as a single list of all the entities and relationships identified in step 1 and step 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n######################\n-Examples-\n######################\nExample 1:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor\'s authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan\'s shared commitment to discovery was an unspoken rebellion against Cruz\'s narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. "If this tech can be understood ..." Taylor said, their voice quieter, "It could change the game for us. For all of us."\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor\'s, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n######################\nOutput:\n("entity"<|>"Alex"<|>"person"<|>"Alex is a character who experiences frustration and is observant of the dynamics among other characters.")##\n("entity"<|>"Taylor"<|>"person"<|>"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.")##\n("entity"<|>"Jordan"<|>"person"<|>"Jordan shares a commitment to discovery and  has a significant interaction with Taylor regarding a device.")##\n("entity"<|>"Cruz"<|>"person"<|>"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.")##\n("entity"<|>"The Device"<|>"technology"<|>"The Device is central to the story, with potential game-changing implications, and revered by Taylor.")##\n("relationship"<|>"Alex"<|>"Taylor"<|>"Alex is affected by Taylor\'s authoritarian certainty and observes changes in Taylor\'s attitude towards the device."<|>7)##\n("relationship"<|>"Alex"<|>"Jordan"<|>"Alex and Jordan share a commitment to discovery, which contrasts with Cruz\'s vision."<|>6)##\n("relationship"<|>"Taylor"<|>"Jordan"<|>"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce."<|>8)##\n("relationship"<|>"Jordan"<|>"Cruz"<|>"Jordan\'s commitment to discovery is in rebellion against Cruz\'s vision of control and order."<|>5)##\n("relationship"<|>"Taylor"<|>"The Device"<|>"Taylor shows reverence towards the device, indicating its importance and potential impact."<|>9)<|COMPLETE|>\n################################\nExample 2:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nThey were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols-it demanded a new perspective, a new resolve.\n\nTension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity\'s place in the cosmos or condemn them to ignorance and potential peril.\n\nTheir connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer\'s latter instincts gained precedence- the team\'s mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\n######################\nOutput:\n("entity"<|>"Washington"<|>"location"<|>"Washington is a location where communications are being received, indicating its importance in the decision-making process.")##\n("entity"<|>"Operation: Dulce"<|>"mission"<|>"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.")##\n("entity"<|>"The team"<|>"organization"<|>"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.")##\n("relationship"<|>"The team"<|>"Washington"<|>"The team receives communications from Washington, which influences their decision-making process."<|>7)##\n("relationship"<|>"The team"<|>"Operation: Dulce"<|>"The team is directly involved in operation: Dulce, executing its evolved objectives and activities."<|>9)<|COMPLETE|>\n##############################\nExample 3:\n\nEntity_types: [person, role, technology, organization, event, location, concept]\nText:\nTheir voice slicing through the buzz of activity. "Control may be an illusion when facing an intelligence that literally writes its own rules," they stated stoically, casting a watchful eye over the flurry of data.\n\n"It\'s like it\'s learning to communicate," offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. "This gives talking to strangers\' a whole new meaning."\n\nAlex surveyed his team-each face a study in concentration, determination, and not a small measure of trepidation. "This might well be our first contact," he acknowledged, "And we need to be ready for whatever answers back." \n\nTogether, they stood on the edge of the unknown, forging humanity\'s response to a message from the heavens. The ensuing silence was palpable-a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\n\nThe encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\n######################\nOutput:\n("entity"<|>"Sam Rivera"<|>"person"<|>"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.")##\n("entity"<|>"Alex"<|>"person"<|>"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.")##\n("entity"<|>"Control"<|>"concept"<|>"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.")##\n("entity"<|>"Intelligence"<|>"concept"<|>"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.")##\n("entity"<|>"First Contact"<|>"event"<|>"First Contact is the potential initial communication between humanity and an unknown intelligence.")##\n("entity"<|>"Humanity\'s Response"<|>"event"<|>"Humanity\'s Response is the collective action taken by Alex\'s team in response to a message from an unknown intelligence.")##\n("relationship"<|>"Sam Rivera"<|>"Intelligence"<|>"Sam Rivera is directly involved in the process of learning to communication with the unknown intelligence."<|>9)##\n("relationship"<|>"Alex"<|>"First Contact"<|>"Alex leads the team that might be making the First Contact with the unknown intelligence."<|>10)##\n("relationship"<|>"Alex"<|>"Humanity\'s Response"<|>"Alex and hist team are the key figures in Humanity\'s Response to the unknown intelligence."<|>8)##\n("relationship"<|>"Control"<|>"Intelligence"<|>"The concept of Control is challenged by the Intelligence that writes its own rules."<|>7)<|COMPLETE|>\n#############################\n-Rea Data-\n###################\nEntity_types: organization,person,geo,event\nText:  by opulence.\n\nBack on the ground, Lucy stroked a Chinese screen adorned with phoenixes, all plumy buoyancy and no terrestrial concerns.\n\nI love phoenixes, Mum said, her gentle eyes bright. Fresh starts!\n\nBut Mum never managed to get her phoenix act off the ground.\n\nSuddenly I thought, Lucy, my little light, why have I never seen it before? These objects are shrouded with spectres of discord! I married the most benevolent man, but never dared to have children. Memories always held me back.\n\n*******\n\n*******\n\nSelling Dads trophies raised enough for a memorial.\n\nNext to my garden pond, graceful wings outstretched and lovely as Mum, a marble phoenix heads for freedom.\n\n\nBarbara was born in Malaysia and grew up there and in Singapore. She now lives in England. Publishers of her work include Ad Hoc Fiction, Quarterly Literary Review Singapore, Reflex Fiction, Cranked Anvil, Anak Sastra, East Of The Web and Flash 500.\n\n@BarbKuessnerH\n\n*\n\nPhoto  Stephen Kennedy  flickr\n\nFLASH FICTION / MAILING LIST / SUBMIT / CURRENT COMPETITION / PREVIOUS COMPETITIONS / CRITIQUE SERVICE / BOOKSHOP / TWITTER / INSTAGRAM / BSKY.SOCIAL / DONATE / LINKS/COMPS/INFO / THE FREE FUTURE FOUNDATION\n\n###################\nOutput:'}.
21:43:50,413 assistant.memory.graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input_': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\nFormat each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in English as a single list of all the entities and relationships identified in step 1 and step 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n######################\n-Examples-\n######################\nExample 1:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor\'s authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan\'s shared commitment to discovery was an unspoken rebellion against Cruz\'s narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. "If this tech can be understood ..." Taylor said, their voice quieter, "It could change the game for us. For all of us."\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor\'s, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n######################\nOutput:\n("entity"<|>"Alex"<|>"person"<|>"Alex is a character who experiences frustration and is observant of the dynamics among other characters.")##\n("entity"<|>"Taylor"<|>"person"<|>"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.")##\n("entity"<|>"Jordan"<|>"person"<|>"Jordan shares a commitment to discovery and  has a significant interaction with Taylor regarding a device.")##\n("entity"<|>"Cruz"<|>"person"<|>"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.")##\n("entity"<|>"The Device"<|>"technology"<|>"The Device is central to the story, with potential game-changing implications, and revered by Taylor.")##\n("relationship"<|>"Alex"<|>"Taylor"<|>"Alex is affected by Taylor\'s authoritarian certainty and observes changes in Taylor\'s attitude towards the device."<|>7)##\n("relationship"<|>"Alex"<|>"Jordan"<|>"Alex and Jordan share a commitment to discovery, which contrasts with Cruz\'s vision."<|>6)##\n("relationship"<|>"Taylor"<|>"Jordan"<|>"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce."<|>8)##\n("relationship"<|>"Jordan"<|>"Cruz"<|>"Jordan\'s commitment to discovery is in rebellion against Cruz\'s vision of control and order."<|>5)##\n("relationship"<|>"Taylor"<|>"The Device"<|>"Taylor shows reverence towards the device, indicating its importance and potential impact."<|>9)<|COMPLETE|>\n################################\nExample 2:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nThey were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols-it demanded a new perspective, a new resolve.\n\nTension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity\'s place in the cosmos or condemn them to ignorance and potential peril.\n\nTheir connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer\'s latter instincts gained precedence- the team\'s mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\n######################\nOutput:\n("entity"<|>"Washington"<|>"location"<|>"Washington is a location where communications are being received, indicating its importance in the decision-making process.")##\n("entity"<|>"Operation: Dulce"<|>"mission"<|>"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.")##\n("entity"<|>"The team"<|>"organization"<|>"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.")##\n("relationship"<|>"The team"<|>"Washington"<|>"The team receives communications from Washington, which influences their decision-making process."<|>7)##\n("relationship"<|>"The team"<|>"Operation: Dulce"<|>"The team is directly involved in operation: Dulce, executing its evolved objectives and activities."<|>9)<|COMPLETE|>\n##############################\nExample 3:\n\nEntity_types: [person, role, technology, organization, event, location, concept]\nText:\nTheir voice slicing through the buzz of activity. "Control may be an illusion when facing an intelligence that literally writes its own rules," they stated stoically, casting a watchful eye over the flurry of data.\n\n"It\'s like it\'s learning to communicate," offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. "This gives talking to strangers\' a whole new meaning."\n\nAlex surveyed his team-each face a study in concentration, determination, and not a small measure of trepidation. "This might well be our first contact," he acknowledged, "And we need to be ready for whatever answers back." \n\nTogether, they stood on the edge of the unknown, forging humanity\'s response to a message from the heavens. The ensuing silence was palpable-a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\n\nThe encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\n######################\nOutput:\n("entity"<|>"Sam Rivera"<|>"person"<|>"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.")##\n("entity"<|>"Alex"<|>"person"<|>"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.")##\n("entity"<|>"Control"<|>"concept"<|>"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.")##\n("entity"<|>"Intelligence"<|>"concept"<|>"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.")##\n("entity"<|>"First Contact"<|>"event"<|>"First Contact is the potential initial communication between humanity and an unknown intelligence.")##\n("entity"<|>"Humanity\'s Response"<|>"event"<|>"Humanity\'s Response is the collective action taken by Alex\'s team in response to a message from an unknown intelligence.")##\n("relationship"<|>"Sam Rivera"<|>"Intelligence"<|>"Sam Rivera is directly involved in the process of learning to communication with the unknown intelligence."<|>9)##\n("relationship"<|>"Alex"<|>"First Contact"<|>"Alex leads the team that might be making the First Contact with the unknown intelligence."<|>10)##\n("relationship"<|>"Alex"<|>"Humanity\'s Response"<|>"Alex and hist team are the key figures in Humanity\'s Response to the unknown intelligence."<|>8)##\n("relationship"<|>"Control"<|>"Intelligence"<|>"The concept of Control is challenged by the Intelligence that writes its own rules."<|>7)<|COMPLETE|>\n#############################\n-Rea Data-\n###################\nEntity_types: organization,person,geo,event\nText: y pointed to a Dutch ceiling lamp of wrought iron. Can I stand on the chair and dust that?\n\nI didnt want to be Boring Auntie Who Always Says No, so I held her legs and supervised her flourishing with a feather duster. The lamp swung wildly.\n\nHelena, youve got to see this! Its a bargain\n\nDarling, we cant afford it!\n\n**\n\nYoure so bone-achingly pedestrian!\n\nIf Mr Ramasamy throws us out because we owe him rent, we will be pedestrians! And itll be your fault!\n\nJust for once, Mums eyes turned tar-black with anger, making Dad recoil.\n\nWhenever Mum tried to leave, something got snagged. She must have felt lost in the rainforest: oppressed, frightened, enervated.\n\nUntil Dad met tempestuous French Irne on a flight to Singapore and was entranced by her air of entitled flamboyance. He died cash-poor but surrounded by opulence.\n\nBack on the ground, Lucy stroked a Chinese screen adorned with phoenixes, all plumy buoyancy and no terrestrial concerns.\n\nI love phoenixes, Mum said, her gentle eyes bright. Fresh starts!\n\nBut Mum never managed to get her phoenix act off the ground.\n\nSuddenly I thought, Lucy, my little light, why have I never seen it before? These objects are shrouded with spectres of discord! I married the most benevolent man, but never\n###################\nOutput:'}.
21:43:50,417 assistant.memory.graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input_': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\nFormat each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in English as a single list of all the entities and relationships identified in step 1 and step 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n######################\n-Examples-\n######################\nExample 1:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor\'s authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan\'s shared commitment to discovery was an unspoken rebellion against Cruz\'s narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. "If this tech can be understood ..." Taylor said, their voice quieter, "It could change the game for us. For all of us."\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor\'s, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n######################\nOutput:\n("entity"<|>"Alex"<|>"person"<|>"Alex is a character who experiences frustration and is observant of the dynamics among other characters.")##\n("entity"<|>"Taylor"<|>"person"<|>"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.")##\n("entity"<|>"Jordan"<|>"person"<|>"Jordan shares a commitment to discovery and  has a significant interaction with Taylor regarding a device.")##\n("entity"<|>"Cruz"<|>"person"<|>"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.")##\n("entity"<|>"The Device"<|>"technology"<|>"The Device is central to the story, with potential game-changing implications, and revered by Taylor.")##\n("relationship"<|>"Alex"<|>"Taylor"<|>"Alex is affected by Taylor\'s authoritarian certainty and observes changes in Taylor\'s attitude towards the device."<|>7)##\n("relationship"<|>"Alex"<|>"Jordan"<|>"Alex and Jordan share a commitment to discovery, which contrasts with Cruz\'s vision."<|>6)##\n("relationship"<|>"Taylor"<|>"Jordan"<|>"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce."<|>8)##\n("relationship"<|>"Jordan"<|>"Cruz"<|>"Jordan\'s commitment to discovery is in rebellion against Cruz\'s vision of control and order."<|>5)##\n("relationship"<|>"Taylor"<|>"The Device"<|>"Taylor shows reverence towards the device, indicating its importance and potential impact."<|>9)<|COMPLETE|>\n################################\nExample 2:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nThey were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols-it demanded a new perspective, a new resolve.\n\nTension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity\'s place in the cosmos or condemn them to ignorance and potential peril.\n\nTheir connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer\'s latter instincts gained precedence- the team\'s mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\n######################\nOutput:\n("entity"<|>"Washington"<|>"location"<|>"Washington is a location where communications are being received, indicating its importance in the decision-making process.")##\n("entity"<|>"Operation: Dulce"<|>"mission"<|>"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.")##\n("entity"<|>"The team"<|>"organization"<|>"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.")##\n("relationship"<|>"The team"<|>"Washington"<|>"The team receives communications from Washington, which influences their decision-making process."<|>7)##\n("relationship"<|>"The team"<|>"Operation: Dulce"<|>"The team is directly involved in operation: Dulce, executing its evolved objectives and activities."<|>9)<|COMPLETE|>\n##############################\nExample 3:\n\nEntity_types: [person, role, technology, organization, event, location, concept]\nText:\nTheir voice slicing through the buzz of activity. "Control may be an illusion when facing an intelligence that literally writes its own rules," they stated stoically, casting a watchful eye over the flurry of data.\n\n"It\'s like it\'s learning to communicate," offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. "This gives talking to strangers\' a whole new meaning."\n\nAlex surveyed his team-each face a study in concentration, determination, and not a small measure of trepidation. "This might well be our first contact," he acknowledged, "And we need to be ready for whatever answers back." \n\nTogether, they stood on the edge of the unknown, forging humanity\'s response to a message from the heavens. The ensuing silence was palpable-a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\n\nThe encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\n######################\nOutput:\n("entity"<|>"Sam Rivera"<|>"person"<|>"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.")##\n("entity"<|>"Alex"<|>"person"<|>"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.")##\n("entity"<|>"Control"<|>"concept"<|>"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.")##\n("entity"<|>"Intelligence"<|>"concept"<|>"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.")##\n("entity"<|>"First Contact"<|>"event"<|>"First Contact is the potential initial communication between humanity and an unknown intelligence.")##\n("entity"<|>"Humanity\'s Response"<|>"event"<|>"Humanity\'s Response is the collective action taken by Alex\'s team in response to a message from an unknown intelligence.")##\n("relationship"<|>"Sam Rivera"<|>"Intelligence"<|>"Sam Rivera is directly involved in the process of learning to communication with the unknown intelligence."<|>9)##\n("relationship"<|>"Alex"<|>"First Contact"<|>"Alex leads the team that might be making the First Contact with the unknown intelligence."<|>10)##\n("relationship"<|>"Alex"<|>"Humanity\'s Response"<|>"Alex and hist team are the key figures in Humanity\'s Response to the unknown intelligence."<|>8)##\n("relationship"<|>"Control"<|>"Intelligence"<|>"The concept of Control is challenged by the Intelligence that writes its own rules."<|>7)<|COMPLETE|>\n#############################\n-Rea Data-\n###################\nEntity_types: organization,person,geo,event\nText: \ufeffAntiques And Ashes by Barbara Kuessner Hughes\nJuly 8, 2024/No Comments\nMy inheritance had just been delivered and was clogging my little house. Pewter, porcelain, teak. Sandalwood, silver, batik\n\nI watched my seven-year-old nieces eyes dart from curio to curio.\n\nThese things belonged to your grandparents, I explained.\n\nRoderick and Helena. Theyre dead, Lucy recited, jiggling.\n\nDad ran a grocery import business in Kuala Lumpur. I dont know how; he was always elsewhere, haggling. The objects traced a map of his movements around Peninsula Malaysia. Ipoh, George Town, Melaka, Kelantan\n\nLucy poked a green-and-yellow rattan box.\n\nYour grandma got that in Port Dickson, when I was little, I said.\n\n*;\n\nMidday heat saturated the shade of the restaurant. Dad poured himself another beer, his heavy jaw and iron-filing hair radiating sullenness. Mousy chignon turning to string, Mum abandoned her fried rice and fled the table. My brother Thomas faked obliviousness. My sister Miranda whimpered. We watched Mum, fragile in a tulip-print shift, flit across scorching sand and encounter the boxs weaver, a shrewd-faced Malay matriarch who discerned her distress.\n\nLucy twirled towards a red lacquer basket embell\n###################\nOutput:'}.
21:44:11,238 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
21:44:11,249 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries             took 20.88799999999992. input_tokens=2237, output_tokens=570.
21:44:11,532 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
21:44:11,535 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries             took 19.145000000000437. input_tokens=2236, output_tokens=525.
21:44:17,197 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
21:44:17,207 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries             took 24.863999999999578. input_tokens=2220, output_tokens=454.
21:44:20,230 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
21:44:20,233 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries             took 28.298999999999978. input_tokens=2236, output_tokens=609.
10:36:32,443 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
10:36:32,465 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:36:32,468 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
10:36:32,519 assistant.memory.graphrag.index.run INFO Running pipeline.
10:36:32,520 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
10:36:32,520 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
10:36:32,520 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
10:36:32,522 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
10:36:32,522 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
10:36:32,531 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
10:36:32,538 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
10:36:32,538 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
10:36:44,955 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
10:36:51,763 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
10:36:57,718 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:37:01,719 assistant.memory.graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
10:37:01,720 assistant.memory.graphrag.index.run INFO read table form storage: create_base_text_units.parquet.
10:37:20,269 datashaper.workflow.workflow INFO executing verb entity_extract
10:37:40,433 assistant.memory.graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
10:37:40,478 assistant.memory.graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
10:37:40,479 assistant.memory.graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
10:40:28,294 datashaper.workflow.workflow INFO executing verb merge_graphs
10:48:13,261 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
10:48:13,283 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:48:13,285 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
10:48:13,290 assistant.memory.graphrag.index.run INFO Running pipeline.
10:48:13,290 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
10:48:13,290 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
10:48:13,290 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
10:48:13,291 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
10:48:13,292 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
10:48:13,297 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
10:48:13,302 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
10:48:13,302 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
10:48:17,283 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
10:48:17,284 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
10:48:28,820 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:48:28,822 assistant.memory.graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
10:48:28,823 assistant.memory.graphrag.index.run INFO read table form storage: create_base_text_units.parquet.
10:48:31,82 datashaper.workflow.workflow INFO executing verb entity_extract
10:48:32,3 assistant.memory.graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
10:48:32,41 assistant.memory.graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
10:48:32,41 assistant.memory.graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
11:02:38,302 datashaper.workflow.workflow INFO executing verb merge_graphs
11:02:39,712 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
11:02:41,823 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
11:02:41,826 assistant.memory.graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities'].
11:02:41,828 assistant.memory.graphrag.index.run INFO read table form storage: create_base_extracted_entities.parquet.
11:02:44,475 datashaper.workflow.workflow INFO executing verb summarize_descriptions
11:02:48,868 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:48,888 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 3.1270000000004075. input_tokens=160, output_tokens=44.
11:02:50,30 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:50,37 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 4.219000000000051. input_tokens=167, output_tokens=77.
11:02:50,189 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:50,196 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 4.402000000000044. input_tokens=179, output_tokens=98.
11:02:50,261 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:50,267 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 4.528999999999996. input_tokens=193, output_tokens=87.
11:02:50,360 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:50,367 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 4.561000000000149. input_tokens=172, output_tokens=94.
11:02:50,612 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:50,619 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 4.846000000000004. input_tokens=198, output_tokens=111.
11:02:50,930 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:50,937 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 5.187000000000353. input_tokens=158, output_tokens=74.
11:02:51,55 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:51,63 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 5.232000000000426. input_tokens=178, output_tokens=102.
11:02:51,572 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:51,578 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 5.8969999999999345. input_tokens=230, output_tokens=130.
11:02:52,368 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
11:02:52,377 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries             took 6.592999999999847. input_tokens=182, output_tokens=157.
11:04:18,510 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
11:04:18,531 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
11:04:18,533 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
11:04:18,538 assistant.memory.graphrag.index.run INFO Running pipeline.
11:04:18,538 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
11:04:18,538 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
11:04:18,538 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
11:04:18,540 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
11:04:18,540 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
11:04:18,546 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
11:04:18,550 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
11:04:18,550 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
11:04:35,192 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
11:04:35,194 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
11:04:41,15 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
11:04:41,16 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
11:04:48,542 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
11:04:48,544 assistant.memory.graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities'].
11:04:48,545 assistant.memory.graphrag.index.run INFO read table form storage: create_base_extracted_entities.parquet.
11:04:58,731 datashaper.workflow.workflow INFO executing verb summarize_descriptions
11:06:37,445 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
11:06:37,468 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
11:06:37,470 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
11:06:37,475 assistant.memory.graphrag.index.run INFO Running pipeline.
11:06:37,475 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
11:06:37,476 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
11:06:37,476 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
11:06:37,477 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
11:06:37,477 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
11:06:37,482 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
11:06:37,488 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
11:06:37,488 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
11:06:46,248 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
11:06:46,250 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
11:06:56,36 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
11:06:56,38 assistant.memory.graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
11:06:56,40 assistant.memory.graphrag.index.run INFO read table form storage: create_base_text_units.parquet.
11:07:00,553 datashaper.workflow.workflow INFO executing verb entity_extract
11:07:08,93 assistant.memory.graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
11:07:08,135 assistant.memory.graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
11:07:08,136 assistant.memory.graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
11:07:26,833 datashaper.workflow.workflow INFO executing verb merge_graphs
13:27:00,22 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
13:27:08,632 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
13:30:13,407 assistant.memory.graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities'].
13:30:13,409 assistant.memory.graphrag.index.run INFO read table form storage: create_base_extracted_entities.parquet.
13:30:44,118 datashaper.workflow.workflow INFO executing verb summarize_descriptions
14:00:30,316 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
14:00:40,664 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
14:00:40,665 assistant.memory.graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities'].
14:00:40,666 assistant.memory.graphrag.index.run INFO read table form storage: create_summarized_entities.parquet.
14:01:42,399 datashaper.workflow.workflow INFO executing verb cluster_graph
17:02:10,229 datashaper.workflow.workflow INFO executing verb select
17:04:42,698 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
17:05:31,822 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
17:05:31,824 assistant.memory.graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph'].
17:05:31,825 assistant.memory.graphrag.index.run INFO read table form storage: create_base_entity_graph.parquet.
17:05:35,999 datashaper.workflow.workflow INFO executing verb unpack_graph
17:23:27,624 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
17:23:27,647 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
17:23:27,649 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
17:23:27,654 assistant.memory.graphrag.index.run INFO Running pipeline.
17:23:27,654 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
17:23:27,655 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
17:23:27,655 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
17:23:27,656 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
17:23:27,657 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
17:23:27,663 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
17:23:27,668 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
17:23:27,668 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
17:24:05,855 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
17:24:05,858 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
17:24:07,103 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
17:24:07,104 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
17:24:10,160 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
17:24:10,161 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
17:24:11,872 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
17:24:11,874 assistant.memory.graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities'].
17:24:11,875 assistant.memory.graphrag.index.run INFO read table form storage: create_summarized_entities.parquet.
17:24:15,765 datashaper.workflow.workflow INFO executing verb cluster_graph
17:30:36,82 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
17:30:36,107 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
17:30:36,110 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
17:30:36,116 assistant.memory.graphrag.index.run INFO Running pipeline.
17:30:36,116 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
17:30:36,117 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
17:30:36,117 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
17:30:36,118 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
17:30:36,119 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
17:30:36,125 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
17:30:36,131 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
17:30:36,131 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
17:30:39,520 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
17:30:39,521 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
17:30:41,55 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
17:30:41,57 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
17:30:44,151 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
17:30:44,152 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
17:30:47,300 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
17:30:47,301 assistant.memory.graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities'].
17:30:47,302 assistant.memory.graphrag.index.run INFO read table form storage: create_summarized_entities.parquet.
17:30:59,718 datashaper.workflow.workflow INFO executing verb cluster_graph
17:32:49,616 datashaper.workflow.workflow INFO executing verb select
17:32:50,559 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
17:33:15,536 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
17:33:19,597 assistant.memory.graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph'].
17:33:19,599 assistant.memory.graphrag.index.run INFO read table form storage: create_base_entity_graph.parquet.
17:33:30,906 datashaper.workflow.workflow INFO executing verb unpack_graph
17:36:49,275 datashaper.workflow.workflow INFO executing verb rename
17:39:19,898 datashaper.workflow.workflow INFO executing verb select
17:41:27,76 datashaper.workflow.workflow INFO executing verb dedupe
17:42:22,590 datashaper.workflow.workflow INFO executing verb rename
17:43:01,36 datashaper.workflow.workflow INFO executing verb filter
17:44:51,450 datashaper.workflow.workflow INFO executing verb text_split
17:50:29,909 datashaper.workflow.workflow INFO executing verb drop
17:52:27,158 datashaper.workflow.workflow INFO executing verb merge
17:54:38,641 datashaper.workflow.workflow INFO executing verb text_embed
17:58:13,287 assistant.memory.graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
17:58:13,331 assistant.memory.graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0.
17:58:13,332 assistant.memory.graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25.
17:59:24,798 assistant.memory.graphrag.index.verbs.text.embed.strategies.openai INFO embedding 26 inputs via 26 snippets using 2 batches. max_batch_size=16, max_tokens=8191
18:00:00,73 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:00:00,343 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:00:00,403 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries             took 1.8099999999976717. input_tokens=364, output_tokens=0.
18:00:00,892 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries             took 2.342000000000553. input_tokens=1007, output_tokens=0.
18:02:32,556 datashaper.workflow.workflow INFO executing verb drop
18:05:01,9 datashaper.workflow.workflow INFO executing verb filter
18:06:43,342 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
18:07:01,427 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
18:07:01,429 assistant.memory.graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph'].
18:07:01,429 assistant.memory.graphrag.index.run INFO read table form storage: create_base_entity_graph.parquet.
18:07:06,268 datashaper.workflow.workflow INFO executing verb layout_graph
09:38:05,986 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
09:38:06,8 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
09:38:06,11 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
09:38:06,62 assistant.memory.graphrag.index.run INFO Running pipeline.
09:38:06,63 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
09:38:06,63 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
09:38:06,63 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
09:38:06,65 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
09:38:06,65 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
09:38:06,73 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
09:38:06,80 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
09:38:06,81 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
09:44:51,703 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
09:44:51,705 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
09:44:53,892 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
09:44:53,894 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
09:44:55,368 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
09:44:55,370 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
09:44:56,494 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
09:44:56,495 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
09:44:58,295 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
09:44:58,297 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
09:44:59,839 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
09:44:59,841 assistant.memory.graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph'].
09:44:59,842 assistant.memory.graphrag.index.run INFO read table form storage: create_base_entity_graph.parquet.
09:45:04,746 datashaper.workflow.workflow INFO executing verb layout_graph
10:21:18,144 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
10:21:18,166 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:21:18,168 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
10:21:18,172 assistant.memory.graphrag.index.run INFO Running pipeline.
10:21:18,173 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
10:21:18,173 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
10:21:18,173 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
10:21:18,174 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
10:21:18,175 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
10:21:18,180 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
10:21:18,184 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
10:21:18,184 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
10:21:20,780 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
10:21:20,781 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
10:21:21,660 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:21:21,661 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
10:21:22,425 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
10:21:22,426 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
10:21:23,257 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
10:21:23,258 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
10:21:23,969 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
10:21:23,971 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
10:21:24,803 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
10:21:24,805 assistant.memory.graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph'].
10:21:24,806 assistant.memory.graphrag.index.run INFO read table form storage: create_base_entity_graph.parquet.
10:21:26,439 datashaper.workflow.workflow INFO executing verb layout_graph
10:45:58,624 datashaper.workflow.workflow INFO executing verb unpack_graph
10:52:55,786 datashaper.workflow.workflow INFO executing verb unpack_graph
10:55:34,145 datashaper.workflow.workflow INFO executing verb filter
11:02:58,773 datashaper.workflow.workflow INFO executing verb drop
11:04:25,952 datashaper.workflow.workflow INFO executing verb select
11:05:41,280 datashaper.workflow.workflow INFO executing verb rename
11:06:47,272 datashaper.workflow.workflow INFO executing verb convert
11:08:05,753 datashaper.workflow.workflow INFO executing verb join
11:13:24,415 datashaper.workflow.workflow INFO executing verb rename
11:14:56,636 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
11:14:58,703 assistant.memory.graphrag.index.run INFO Running workflow: create_final_communities...
11:14:58,705 assistant.memory.graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph'].
11:14:58,706 assistant.memory.graphrag.index.run INFO read table form storage: create_base_entity_graph.parquet.
11:15:02,809 datashaper.workflow.workflow INFO executing verb unpack_graph
11:20:09,151 datashaper.workflow.workflow INFO executing verb unpack_graph
11:21:28,850 datashaper.workflow.workflow INFO executing verb aggregate_override
11:31:50,609 datashaper.workflow.workflow INFO executing verb join
11:45:48,748 datashaper.workflow.workflow INFO executing verb join
11:50:30,847 datashaper.workflow.workflow INFO executing verb concat
11:56:37,462 datashaper.workflow.workflow INFO executing verb filter
12:06:43,573 datashaper.workflow.workflow INFO executing verb aggregate_override
12:21:10,640 datashaper.workflow.workflow INFO executing verb join
12:25:42,431 datashaper.workflow.workflow INFO executing verb filter
12:27:12,511 datashaper.workflow.workflow INFO executing verb fill
12:28:11,146 datashaper.workflow.workflow INFO executing verb merge
12:30:40,586 datashaper.workflow.workflow INFO executing verb copy
12:32:10,282 datashaper.workflow.workflow INFO executing verb select
12:38:14,256 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
12:38:20,447 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
12:38:20,450 assistant.memory.graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities'].
12:38:20,450 assistant.memory.graphrag.index.run INFO read table form storage: create_final_entities.parquet.
12:38:22,94 datashaper.workflow.workflow INFO executing verb select
12:41:14,661 datashaper.workflow.workflow INFO executing verb unroll
12:45:57,532 datashaper.workflow.workflow INFO executing verb aggregate_override
12:52:11,34 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
12:52:19,843 assistant.memory.graphrag.index.run INFO Running workflow: create_final_relationships...
12:52:19,845 assistant.memory.graphrag.index.run INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes'].
12:52:19,845 assistant.memory.graphrag.index.run INFO read table form storage: create_base_entity_graph.parquet.
12:52:19,858 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
12:52:25,552 datashaper.workflow.workflow INFO executing verb unpack_graph
13:45:08,221 datashaper.workflow.workflow INFO executing verb filter
13:49:04,291 datashaper.workflow.workflow INFO executing verb rename
13:51:45,734 datashaper.workflow.workflow INFO executing verb filter
13:52:37,549 datashaper.workflow.workflow INFO executing verb drop
13:57:57,971 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
14:16:41,166 datashaper.workflow.workflow INFO executing verb convert
14:38:23,185 datashaper.workflow.workflow INFO executing verb convert
14:45:08,248 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
14:45:09,743 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
14:45:09,744 assistant.memory.graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships'].
14:45:09,745 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
14:45:11,535 datashaper.workflow.workflow INFO executing verb select
14:49:08,33 datashaper.workflow.workflow INFO executing verb unroll
14:50:09,936 datashaper.workflow.workflow INFO executing verb aggregate_override
14:56:29,815 datashaper.workflow.workflow INFO executing verb select
14:59:03,921 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
14:59:05,83 assistant.memory.graphrag.index.run INFO Running workflow: create_final_community_reports...
14:59:05,85 assistant.memory.graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes'].
14:59:05,86 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
14:59:05,101 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
14:59:06,675 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
15:18:54,102 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
15:24:00,711 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
15:34:44,3 datashaper.workflow.workflow INFO executing verb prepare_community_reports
15:34:44,8 assistant.memory.graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
15:36:29,931 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
15:36:29,953 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
15:36:29,955 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
15:36:29,959 assistant.memory.graphrag.index.run INFO Running pipeline.
15:36:29,960 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
15:36:29,960 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
15:36:29,960 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
15:36:29,961 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
15:36:29,962 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
15:36:29,967 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
15:36:29,972 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
15:36:29,973 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
15:36:47,799 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
15:36:47,800 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
15:36:49,412 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
15:36:49,413 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
15:36:51,447 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
15:36:51,448 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
15:36:53,366 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
15:36:53,367 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
15:36:54,916 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
15:36:54,917 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
15:36:56,488 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
15:36:56,489 assistant.memory.graphrag.index.run INFO Skipping create_final_nodes because it already exists.
15:36:57,736 assistant.memory.graphrag.index.run INFO Running workflow: create_final_communities...
15:36:57,738 assistant.memory.graphrag.index.run INFO Skipping create_final_communities because it already exists.
15:36:59,317 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
15:36:59,319 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
15:37:00,709 assistant.memory.graphrag.index.run INFO Running workflow: create_final_relationships...
15:37:00,710 assistant.memory.graphrag.index.run INFO Skipping create_final_relationships because it already exists.
15:37:02,35 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
15:37:02,36 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
15:37:05,357 assistant.memory.graphrag.index.run INFO Running workflow: create_final_community_reports...
15:37:05,359 assistant.memory.graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
15:37:05,360 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
15:37:05,385 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
15:37:11,551 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
15:37:18,460 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
15:37:26,572 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
15:39:05,303 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
15:39:05,325 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
15:39:05,327 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
15:39:05,332 assistant.memory.graphrag.index.run INFO Running pipeline.
15:39:05,332 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
15:39:05,333 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
15:39:05,333 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
15:39:05,334 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
15:39:05,335 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
15:39:05,340 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
15:39:05,345 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
15:39:05,345 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
15:39:09,551 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
15:39:09,553 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
15:39:11,982 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
15:39:11,983 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
15:39:13,322 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
15:39:13,323 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
15:39:15,145 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
15:39:15,146 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
15:39:16,126 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
15:39:16,128 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
15:39:17,170 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
15:39:17,172 assistant.memory.graphrag.index.run INFO Skipping create_final_nodes because it already exists.
15:39:17,972 assistant.memory.graphrag.index.run INFO Running workflow: create_final_communities...
15:39:17,973 assistant.memory.graphrag.index.run INFO Skipping create_final_communities because it already exists.
15:39:18,906 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
15:39:18,907 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
15:39:19,688 assistant.memory.graphrag.index.run INFO Running workflow: create_final_relationships...
15:39:19,689 assistant.memory.graphrag.index.run INFO Skipping create_final_relationships because it already exists.
15:39:20,537 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
15:39:20,538 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
15:39:21,409 assistant.memory.graphrag.index.run INFO Running workflow: create_final_community_reports...
15:39:21,410 assistant.memory.graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes'].
15:39:21,411 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
15:39:21,438 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
15:39:25,586 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
15:39:41,511 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
15:39:58,626 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
15:41:36,54 datashaper.workflow.workflow INFO executing verb prepare_community_reports
15:48:08,219 assistant.memory.graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
16:55:00,667 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
16:55:00,692 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
16:55:00,694 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
16:55:00,699 assistant.memory.graphrag.index.run INFO Running pipeline.
16:55:00,700 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
16:55:00,700 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
16:55:00,700 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
16:55:00,702 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
16:55:00,702 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
16:55:00,709 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
16:55:00,713 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
16:55:00,714 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
16:55:03,499 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
16:55:03,501 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
16:55:04,410 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
16:55:04,411 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
16:55:04,986 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
16:55:04,988 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
16:55:06,319 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
16:55:06,321 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
16:55:07,767 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
16:55:07,769 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
16:55:08,596 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
16:55:08,597 assistant.memory.graphrag.index.run INFO Skipping create_final_nodes because it already exists.
16:55:09,396 assistant.memory.graphrag.index.run INFO Running workflow: create_final_communities...
16:55:09,398 assistant.memory.graphrag.index.run INFO Skipping create_final_communities because it already exists.
16:55:10,148 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
16:55:10,150 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
16:55:11,73 assistant.memory.graphrag.index.run INFO Running workflow: create_final_relationships...
16:55:11,75 assistant.memory.graphrag.index.run INFO Skipping create_final_relationships because it already exists.
16:55:11,846 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
16:55:11,848 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
16:55:12,699 assistant.memory.graphrag.index.run INFO Running workflow: create_final_community_reports...
16:55:12,700 assistant.memory.graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
16:55:12,701 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
16:55:12,726 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
16:55:16,121 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
16:55:17,447 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
16:55:18,708 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
16:55:20,41 datashaper.workflow.workflow INFO executing verb prepare_community_reports
16:55:20,655 assistant.memory.graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
17:09:15,936 datashaper.workflow.workflow INFO executing verb create_community_reports
17:14:47,451 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
17:14:47,473 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
17:14:47,475 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
17:14:47,480 assistant.memory.graphrag.index.run INFO Running pipeline.
17:14:47,480 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
17:14:47,480 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
17:14:47,481 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
17:14:47,482 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
17:14:47,483 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
17:14:47,488 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
17:14:47,492 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
17:14:47,493 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
17:15:20,633 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
17:15:20,635 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
17:15:21,782 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
17:15:21,783 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
17:15:22,817 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
17:15:22,818 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
17:15:24,72 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
17:15:24,74 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
17:15:25,62 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
17:15:25,63 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
17:15:26,81 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
17:15:26,82 assistant.memory.graphrag.index.run INFO Skipping create_final_nodes because it already exists.
17:15:29,985 assistant.memory.graphrag.index.run INFO Running workflow: create_final_communities...
17:15:29,986 assistant.memory.graphrag.index.run INFO Skipping create_final_communities because it already exists.
17:15:32,726 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
17:15:32,727 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
17:15:33,766 assistant.memory.graphrag.index.run INFO Running workflow: create_final_relationships...
17:15:33,767 assistant.memory.graphrag.index.run INFO Skipping create_final_relationships because it already exists.
17:15:34,615 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
17:15:34,617 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
17:15:35,507 assistant.memory.graphrag.index.run INFO Running workflow: create_final_community_reports...
17:15:35,509 assistant.memory.graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
17:15:35,510 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
17:15:35,537 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
17:15:43,77 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
17:15:49,160 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
17:16:09,622 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
17:19:12,782 datashaper.workflow.workflow INFO executing verb prepare_community_reports
17:19:29,489 assistant.memory.graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
17:21:48,607 datashaper.workflow.workflow INFO executing verb create_community_reports
17:24:03,285 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
17:24:03,307 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
17:24:03,309 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
17:24:03,313 assistant.memory.graphrag.index.run INFO Running pipeline.
17:24:03,313 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
17:24:03,314 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
17:24:03,314 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
17:24:03,315 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
17:24:03,315 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
17:24:03,321 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
17:24:03,326 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
17:24:03,326 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
17:24:05,671 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
17:24:05,672 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
17:24:06,535 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
17:24:06,536 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
17:24:07,763 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
17:24:07,764 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
17:24:10,645 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
17:24:10,646 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
17:24:12,861 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
17:24:12,863 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
17:24:13,657 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
17:24:13,659 assistant.memory.graphrag.index.run INFO Skipping create_final_nodes because it already exists.
17:24:14,897 assistant.memory.graphrag.index.run INFO Running workflow: create_final_communities...
17:24:14,898 assistant.memory.graphrag.index.run INFO Skipping create_final_communities because it already exists.
17:24:15,794 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
17:24:15,795 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
17:24:16,667 assistant.memory.graphrag.index.run INFO Running workflow: create_final_relationships...
17:24:16,668 assistant.memory.graphrag.index.run INFO Skipping create_final_relationships because it already exists.
17:24:17,684 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
17:24:17,686 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
17:24:18,965 assistant.memory.graphrag.index.run INFO Running workflow: create_final_community_reports...
17:24:18,966 assistant.memory.graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes'].
17:24:18,969 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
17:24:18,994 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
17:24:27,583 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
17:24:31,346 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
17:24:37,296 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
17:28:22,247 datashaper.workflow.workflow INFO executing verb prepare_community_reports
17:28:24,985 assistant.memory.graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
17:28:49,57 datashaper.workflow.workflow INFO executing verb create_community_reports
17:38:13,577 assistant.memory.graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
17:38:13,621 assistant.memory.graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
17:38:13,622 assistant.memory.graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
17:39:09,776 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 403 Forbidden"
17:39:09,804 assistant.memory.graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input_': '\nYou are an AI assistant that helps a human analyst to perform general information discovery. Information discovery is the process of identifying and assessing relevant information associated with certain entities (e.g., organizations and individuals) within a network.\n\n# Goal\nWrite a comprehensive report of a community, given a list of entities that belong to the community as well as their relationships and optional associated claims. The report will be used to inform decision-makers about information associated with the community abd their potential impact. The content of this report includes an overview of the community\'s key entities, their legal compliance, technical capabilities, reputation, and noteworthy claims.\n\n# Report Structure\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community. IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary": <insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary": <insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor Example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\n\n# Example Input\n-----------\nText:\n\nEntities\n\nid,entity,description\n5,VERDANT OASIS PLAZA,Verdant Oasis Plaza is the location of the Unity March\n6,HARMONY ASSEMBLY,Harmony Assembly is an organization that is holding a march at Verdant Oasis Plaza\n\nRelationships\n\nid,source,target,description\n37,VERDANT OASIS PLAZA,UNITY MARCH,Verdant Oasis Plaza is the location of the Unity March\n38,VERDANT OASIS PLAZA,HARMONY ASSEMBLY,Harmony Assembly is holding a march at Verdant Oasis Plaza\n39,VERDANT OASIS PLAZA,UNITY MARCH,The Unity March is taking place at Verdant Oasis Plaza\n40,VERDANT OASIS PLAZA,TRIBUNE SPOTLIGHT,Tribune Spotlight is reporting on the Unity march taking place at Verdant Oasis Plaza\n41,VERDANT OASIS PLAZA,BAILEY ASADI,Bailey Asadi is speaking at Verdant Oasis Plaza about the march\n43,HARMONY ASSEMBLY,UNITY MARCH, Harmony Assembly is organizing the Unity March\n\nOutput:\n{{\n    "title": "Verdant Oasis Plaza and Unity March",\n    "summary": "The community revolves around the Verdant Oasis Plaza, which is the location of the Unity March.     The plaza has relationships with the Harmony Assembly, Unity March, and Tribune Spotlight, all of which are     associated with the march event.",\n    "rating": 5.0,\n    "rating_explanation": "The impact severity rating is moderate due to the potential for unrest or conflict     during the Unity March.",\n    "findings": [\n        {{\n            "summary": "Verdant Oasis Plaza as the central location",\n            "explanation": "Verdant Oasis Plaza is the central entity in this community, serving as the location             for the Unity March. This plaza is the common link between all other entities, suggesting its             significance in the community. The plaza\'s association with the march could potentially lead to             issues such as public disorder or conflict, depending on the nature of the march and the reactions             it provokes. [Data: Entities (5), Relationships (37, 38, 39, 40, 41, +more)]"\n        }},\n        {{\n            "summary": "Harmony Assembly\'s role in the community",\n            "explanation": "Harmony Assembly is another key entity in this community, being the organizer of             the march at Verdant Oasis Plaza. The nature of Harmony Assembly and its march could be a potential             source of threat, depending on their objectives and the reactions they provoke. The relationship             between Harmony Assembly and the plaza is crucial in understanding the dynamics of this community.             [Data: Entities(6), Relationships (38, 43)]"\n        }},\n        {{\n            "summary": "Unity March as a significant event",\n            "explanation": "The Unity March is a significant event taking place at Verdant Oasis Plaza.             This event is a key factor in the community\'s dynamics and could be a potential source of threat,             depending on the nature of the march and the reactions it provokes. The relationship between the             march and the plaza is crucial in understanding the dynamics of this community. [Data: Relationships (39)]"\n        }},\n        {{\n            "summary": "Role of Tribune Spotlight",\n            "explanation": "Tribune Spotlight is reporting on the Unity March taking place in Verdant Oasis Plaza.             This suggests that the event has attracted media attention, which could amplify its impact on the             community. The role of Tribune Spotlight could be significant in shaping public perception of the event             and the entities involved. [Data: Relationships (40)]"\n        }}\n    ]\n}}\n\n\n# Real Data\n\nUse the following text for your answer. Do not make anything up in your answer.\n\nText:\n-----Entities-----\nhuman_readable_id,title,description,degree\n1,"""LUCY""","Lucy is a seven-year-old character who is deeply associated with a moment of realization regarding her family\'s past and the symbolic significance of phoenixes. She shows a keen interest in exploring and engaging with objects around her, such as the red lacquer basket and the Dutch ceiling lamp, indicating her curiosity and appreciation for the inherited curios. Lucy, being the niece of the narrator, is referred to with affection and is involved in a significant moment of realization about the objects around her. This indicates her close relationship with the narrator and her integral role in uncovering and understanding the layers of her family\'s history and the symbolic meanings embedded in their possessions.",5\n3,"""HELENA""","Helena is depicted as an individual deeply involved in financial discussions, particularly in situations where bargains are being considered. Her involvement indicates a role in decision-making, suggesting she has a keen interest or authority in such matters. Additionally, Helena is identified as one of Lucy\'s grandparents, which also positions her as presumably a parent of the narrator. This multifaceted portrayal highlights Helena\'s active participation in both family dynamics and financial deliberations.",2\n18,"""CHINESE SCREEN""","""A Chinese screen adorned with phoenixes, mentioned in the context of being admired, indicating its cultural and artistic significance.""",1\n22,"""THE MARBLE PHOENIX""","""The Marble Phoenix symbolizes a memorial created from selling Dads trophies, representing freedom and the memory of Mum.""",1\n6,"""PORT DICKSON""","""Port Dickson is mentioned as the place where the narrator\'s grandmother acquired a green-and-yellow rattan box.""",1\n\n\n-----Relationships-----\nhuman_readable_id,source,target,description,rank\n2,"""LUCY""","""MUM""","Lucy and her Mum share a profound relationship, deeply intertwined with the symbolic significance of phoenixes. Lucy often reflects on their bond and how phoenixes, representing rebirth and fresh starts, play a pivotal role in their lives. Mum\'s affection for these mythical creatures and the idea of new beginnings is openly expressed in front of Lucy, showcasing a relationship built on sharing hopes and dreams. This mutual appreciation for the symbolism of phoenixes highlights the depth of their connection and the shared values that underpin their relationship.",10\n1,"""LUCY""","""HELENA""","Lucy and Helena share a familial bond, with Lucy being the granddaughter of Helena. This relationship is characterized by a dynamic where Lucy looks up to Helena, often seeking her permission, which suggests that Helena holds a supervisory or authoritative role within their family. This interaction between them highlights the close and respectful relationship they share, underpinned by familial ties and a clear generational hierarchy.",7\n0,"""LUCY""","""RODERICK""","""Lucy is the granddaughter of Roderick, indicating a family relationship.""",7\n3,"""LUCY""","""CHINESE SCREEN""","""Lucy\'s admiration for the Chinese screen adorned with phoenixes indicates a connection to its symbolic meaning of rebirth and new beginnings.""",6\n4,"""LUCY""","""THE MARBLE PHOENIX""","""The Marble Phoenix represents a significant event in Lucy\'s narrative, symbolizing a memorial and a connection to her family\'s past.""",6\n6,"""HELENA""","""PORT DICKSON""","""Helena acquired a rattan box in Port Dickson, indicating a personal connection to the location.""",3\n\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community. IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary": <insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary": <insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor Example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\nOutput:'}.
17:39:09,805 assistant.memory.graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report.
Traceback (most recent call last):
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 59, in __call__
    await self._llm(
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input_, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input_, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/openai/openai_history_tracking_llm.py", line 34, in __call__
    output = await self._delegate(input_, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/base/caching_llm.py", line 138, in __call__
    result = await self._delegate(input_, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/base/rate_limiting_llm.py", line 210, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/base/rate_limiting_llm.py", line 190, in execute_with_retry
    async for attempt in retryer:
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/site-packages/tenacity/_asyncio.py", line 71, in __anext__
    do = self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/base/rate_limiting_llm.py", line 197, in execute_with_retry
    return await do_attempt(), start_
           ^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/base/rate_limiting_llm.py", line 171, in do_attempt
    return await self._delegate(input_, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/base/base_llm.py", line 59, in __call__
    return await self._invoke_json(input_, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/openai/openai_chat_llm.py", line 106, in _invoke_json
    result = await generate()
             ^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/openai/openai_chat_llm.py", line 93, in generate
    await self._native_json(input_, **{**kwargs, "name": call_name})
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/openai/openai_chat_llm.py", line 128, in _native_json
    result = await self._invoke(
             ^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/base/base_llm.py", line 74, in _invoke
    output = await self._execute_llm(input_, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/PycharmProjects/Assistant/assistant/memory/graphrag/llm/openai/openai_chat_llm.py", line 63, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 1181, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/site-packages/openai/_base_client.py", line 1790, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/site-packages/openai/_base_client.py", line 1493, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/wuzhenglin/anaconda3/envs/Assistant/lib/python3.11/site-packages/openai/_base_client.py", line 1584, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.PermissionDeniedError: Error code: 403 - {'error': {'message': ' https://buyca.tech/buy/24 Your account balance is not sufficient to support this request. Please visit https://buyca.tech/buy/24 to recharge.', 'type': 'chatanywhere_error', 'param': None, 'code': '403 FORBIDDEN'}}
17:39:09,818 assistant.memory.graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None.
17:39:09,818 assistant.memory.graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 2.
17:39:10,251 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 403 Forbidden"
17:39:10,261 assistant.memory.graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input_': '\nYou are an AI assistant that helps a human analyst to perform general information discovery. Information discovery is the process of identifying and assessing relevant information associated with certain entities (e.g., organizations and individuals) within a network.\n\n# Goal\nWrite a comprehensive report of a community, given a list of entities that belong to the community as well as their relationships and optional associated claims. The report will be used to inform decision-makers about information associated with the community abd their potential impact. The content of this report includes an overview of the community\'s key entities, their legal compliance, technical capabilities, reputation, and noteworthy claims.\n\n# Report Structure\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community. IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary": <insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary": <insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor Example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\n\n# Example Input\n-----------\nText:\n\nEntities\n\nid,entity,description\n5,VERDANT OASIS PLAZA,Verdant Oasis Plaza is the location of the Unity March\n6,HARMONY ASSEMBLY,Harmony Assembly is an organization that is holding a march at Verdant Oasis Plaza\n\nRelationships\n\nid,source,target,description\n37,VERDANT OASIS PLAZA,UNITY MARCH,Verdant Oasis Plaza is the location of the Unity March\n38,VERDANT OASIS PLAZA,HARMONY ASSEMBLY,Harmony Assembly is holding a march at Verdant Oasis Plaza\n39,VERDANT OASIS PLAZA,UNITY MARCH,The Unity March is taking place at Verdant Oasis Plaza\n40,VERDANT OASIS PLAZA,TRIBUNE SPOTLIGHT,Tribune Spotlight is reporting on the Unity march taking place at Verdant Oasis Plaza\n41,VERDANT OASIS PLAZA,BAILEY ASADI,Bailey Asadi is speaking at Verdant Oasis Plaza about the march\n43,HARMONY ASSEMBLY,UNITY MARCH, Harmony Assembly is organizing the Unity March\n\nOutput:\n{{\n    "title": "Verdant Oasis Plaza and Unity March",\n    "summary": "The community revolves around the Verdant Oasis Plaza, which is the location of the Unity March.     The plaza has relationships with the Harmony Assembly, Unity March, and Tribune Spotlight, all of which are     associated with the march event.",\n    "rating": 5.0,\n    "rating_explanation": "The impact severity rating is moderate due to the potential for unrest or conflict     during the Unity March.",\n    "findings": [\n        {{\n            "summary": "Verdant Oasis Plaza as the central location",\n            "explanation": "Verdant Oasis Plaza is the central entity in this community, serving as the location             for the Unity March. This plaza is the common link between all other entities, suggesting its             significance in the community. The plaza\'s association with the march could potentially lead to             issues such as public disorder or conflict, depending on the nature of the march and the reactions             it provokes. [Data: Entities (5), Relationships (37, 38, 39, 40, 41, +more)]"\n        }},\n        {{\n            "summary": "Harmony Assembly\'s role in the community",\n            "explanation": "Harmony Assembly is another key entity in this community, being the organizer of             the march at Verdant Oasis Plaza. The nature of Harmony Assembly and its march could be a potential             source of threat, depending on their objectives and the reactions they provoke. The relationship             between Harmony Assembly and the plaza is crucial in understanding the dynamics of this community.             [Data: Entities(6), Relationships (38, 43)]"\n        }},\n        {{\n            "summary": "Unity March as a significant event",\n            "explanation": "The Unity March is a significant event taking place at Verdant Oasis Plaza.             This event is a key factor in the community\'s dynamics and could be a potential source of threat,             depending on the nature of the march and the reactions it provokes. The relationship between the             march and the plaza is crucial in understanding the dynamics of this community. [Data: Relationships (39)]"\n        }},\n        {{\n            "summary": "Role of Tribune Spotlight",\n            "explanation": "Tribune Spotlight is reporting on the Unity March taking place in Verdant Oasis Plaza.             This suggests that the event has attracted media attention, which could amplify its impact on the             community. The role of Tribune Spotlight could be significant in shaping public perception of the event             and the entities involved. [Data: Relationships (40)]"\n        }}\n    ]\n}}\n\n\n# Real Data\n\nUse the following text for your answer. Do not make anything up in your answer.\n\nText:\n-----Entities-----\nhuman_readable_id,title,description,degree\n11,"""DAD""","Dad is depicted as a complex character who, on one hand, is entranced by Irne, leading to a life that ends \'cash-poor but surrounded by opulence\'. This detail highlights the consequences of his life choices, suggesting a man who perhaps pursued passions or investments that did not translate into financial stability, yet allowed him to be surrounded by luxury in some form at the end of his life. On the other hand, Dad is also portrayed as confrontational, particularly in his interactions with Mum, where he accuses her of stinginess. This behavior contributes to the underlying tension within the family, painting a picture of a man who is both captivated by certain desires and ideals, yet also embroiled in familial discord, possibly exacerbated by his own accusations and confrontations.",4\n12,"""CHINESE SHOP ASSISTANT""","""The Chinese shop assistant is perturbed by Dad\'s lack of decorum, indicating a reaction to the family\'s dynamics.""",1\n13,"""MRS KHOO""","""Mrs Khoo is mentioned in a hypothetical context by Dad, referring to the original owner of a wedding gift basket.""",1\n16,"""IRNE""","""Irne is a tempestuous French woman who Dad met on a flight to Singapore, characterized by her entitled flamboyance.""",1\n\n\n-----Relationships-----\nhuman_readable_id,source,target,description,rank\n9,"""MUM""","""DAD""","""Dad\'s confrontational behavior towards Mum highlights the tension between them.""",9\n12,"""DAD""","""CHINESE SHOP ASSISTANT""","""The Chinese Shop Assistant\'s perturbed reaction is directly caused by Dad\'s behavior.""",5\n13,"""DAD""","""MRS KHOO""","""Dad references Mrs Khoo in a hypothetical scenario related to the wedding gift basket, indicating a connection made in conversation.""",5\n14,"""DAD""","""IRNE""","""Dad was entranced by Irne during a flight to Singapore, indicating a significant personal connection between them.""",5\n\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community. IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary": <insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary": <insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor Example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\nOutput:'}.
17:46:12,554 assistant.memory.graphrag.config.read_dotenv INFO Loading pipeline .env file
17:46:12,576 assistant.memory.graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
17:46:12,578 assistant.memory.graphrag.index.create_pipeline_config INFO Skipping workflows 
17:46:12,583 assistant.memory.graphrag.index.run INFO Running pipeline.
17:46:12,583 assistant.memory.graphrag.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
17:46:12,583 assistant.memory.graphrag.index.input.load_input INFO loading input from root_dir=input
17:46:12,584 assistant.memory.graphrag.index.input.load_input INFO using file storage for input.
17:46:12,584 assistant.memory.graphrag.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
17:46:12,585 assistant.memory.graphrag.index.input.text INFO Found text files from input, found [('book.txt', {})].
17:46:12,590 assistant.memory.graphrag.index.input.text INFO Found 1 files, loading 1
17:46:12,595 assistant.memory.graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
17:46:12,595 assistant.memory.graphrag.index.run INFO Final # of rows loaded: 1.
17:46:14,953 assistant.memory.graphrag.index.run INFO Running workflow: create_base_text_units...
17:46:14,954 assistant.memory.graphrag.index.run INFO Skipping create_base_text_units because it already exists.
17:46:15,767 assistant.memory.graphrag.index.run INFO Running workflow: create_base_extracted_entities...
17:46:15,768 assistant.memory.graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists.
17:46:16,596 assistant.memory.graphrag.index.run INFO Running workflow: create_summarized_entities...
17:46:16,597 assistant.memory.graphrag.index.run INFO Skipping create_summarized_entities because it already exists.
17:46:17,359 assistant.memory.graphrag.index.run INFO Running workflow: create_base_entity_graph...
17:46:17,361 assistant.memory.graphrag.index.run INFO Skipping create_base_entity_graph because it already exists.
17:46:18,272 assistant.memory.graphrag.index.run INFO Running workflow: create_final_entities...
17:46:18,274 assistant.memory.graphrag.index.run INFO Skipping create_final_entities because it already exists.
17:46:19,191 assistant.memory.graphrag.index.run INFO Running workflow: create_final_nodes...
17:46:19,193 assistant.memory.graphrag.index.run INFO Skipping create_final_nodes because it already exists.
17:46:20,74 assistant.memory.graphrag.index.run INFO Running workflow: create_final_communities...
17:46:20,75 assistant.memory.graphrag.index.run INFO Skipping create_final_communities because it already exists.
17:46:21,373 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
17:46:21,374 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
17:46:22,749 assistant.memory.graphrag.index.run INFO Running workflow: create_final_relationships...
17:46:22,750 assistant.memory.graphrag.index.run INFO Skipping create_final_relationships because it already exists.
17:46:23,990 assistant.memory.graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
17:46:23,991 assistant.memory.graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
17:46:25,32 assistant.memory.graphrag.index.run INFO Running workflow: create_final_community_reports...
17:46:25,34 assistant.memory.graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes'].
17:46:25,35 assistant.memory.graphrag.index.run INFO read table form storage: create_final_relationships.parquet.
17:46:25,62 assistant.memory.graphrag.index.run INFO read table form storage: create_final_nodes.parquet.
17:46:26,963 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
17:46:28,590 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
17:46:29,795 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
17:46:31,318 datashaper.workflow.workflow INFO executing verb prepare_community_reports
17:46:32,29 assistant.memory.graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
17:46:33,846 datashaper.workflow.workflow INFO executing verb create_community_reports
17:46:34,863 assistant.memory.graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
17:46:34,912 assistant.memory.graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
17:46:34,913 assistant.memory.graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
17:46:46,352 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
17:46:46,375 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries             took 11.376000000000204. input_tokens=2092, output_tokens=349.
17:48:41,790 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
17:48:41,801 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
17:48:41,803 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
17:48:41,811 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries             took 126.88299999999799. input_tokens=2381, output_tokens=750.
17:48:41,814 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries             took 126.85599999999977. input_tokens=2530, output_tokens=729.
17:48:41,817 assistant.memory.graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries             took 126.83499999999913. input_tokens=2671, output_tokens=883.
17:54:50,685 datashaper.workflow.workflow INFO executing verb window
17:56:46,459 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
18:03:44,917 assistant.memory.graphrag.index.run INFO Running workflow: create_final_text_units...
18:03:44,919 assistant.memory.graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids', 'create_base_text_units'].
18:03:44,920 assistant.memory.graphrag.index.run INFO read table form storage: join_text_units_to_entity_ids.parquet.
18:03:44,934 assistant.memory.graphrag.index.run INFO read table form storage: join_text_units_to_relationship_ids.parquet.
18:03:44,943 assistant.memory.graphrag.index.run INFO read table form storage: create_base_text_units.parquet.
18:03:48,835 datashaper.workflow.workflow INFO executing verb select
18:06:27,145 datashaper.workflow.workflow INFO executing verb rename
18:06:58,254 datashaper.workflow.workflow INFO executing verb join
18:11:16,837 datashaper.workflow.workflow INFO executing verb join
18:17:51,514 datashaper.workflow.workflow INFO executing verb aggregate_override
18:21:04,22 datashaper.workflow.workflow INFO executing verb select
18:26:50,993 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
18:26:52,429 assistant.memory.graphrag.index.run INFO Running workflow: create_base_documents...
18:26:52,431 assistant.memory.graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units'].
18:26:52,432 assistant.memory.graphrag.index.run INFO read table form storage: create_final_text_units.parquet.
18:26:56,19 datashaper.workflow.workflow INFO executing verb unroll
18:28:58,551 datashaper.workflow.workflow INFO executing verb select
18:29:57,621 datashaper.workflow.workflow INFO executing verb rename
18:31:58,748 datashaper.workflow.workflow INFO executing verb join
18:35:06,736 datashaper.workflow.workflow INFO executing verb aggregate_override
18:37:36,84 datashaper.workflow.workflow INFO executing verb join
18:39:55,910 datashaper.workflow.workflow INFO executing verb rename
18:40:40,198 datashaper.workflow.workflow INFO executing verb convert
18:45:40,778 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
18:45:43,766 assistant.memory.graphrag.index.run INFO Running workflow: create_final_documents...
18:45:43,768 assistant.memory.graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents'].
18:45:43,769 assistant.memory.graphrag.index.run INFO read table form storage: create_base_documents.parquet.
18:45:48,491 datashaper.workflow.workflow INFO executing verb rename
18:45:49,260 assistant.memory.graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
20:40:36,384 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:40:36,406 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:40:36,409 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:40:36,462 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:40:36,463 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:40:36,463 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:40:36,463 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:40:36,464 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:40:36,465 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:40:36,475 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:40:36,480 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:40:36,480 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:40:36,739 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:40:36,740 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:40:36,972 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:40:36,972 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:40:37,196 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:40:37,197 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:40:37,408 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:40:37,409 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:40:37,622 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:40:37,623 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:40:37,850 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:40:37,851 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:40:38,63 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:40:38,64 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:40:38,296 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:40:38,296 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:40:38,530 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:40:38,531 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:40:38,766 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:40:38,767 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:40:38,996 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:40:38,997 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:40:39,222 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:40:39,223 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
20:40:39,436 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
20:40:39,436 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
20:40:39,653 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
20:40:39,654 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:43:07,901 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:43:07,929 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:43:07,936 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:43:40,142 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:43:40,143 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:43:40,144 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:43:40,144 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:43:40,146 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:43:40,148 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:43:40,161 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:43:40,171 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:43:40,172 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:43:40,434 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:43:40,434 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:43:40,672 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:43:40,673 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:43:40,885 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:43:40,885 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:43:41,116 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:43:41,117 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:43:41,351 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:43:41,352 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:43:41,592 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:43:41,593 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:43:41,833 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:43:41,836 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:43:42,63 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:43:42,63 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:43:42,291 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:43:42,291 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:43:42,569 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:43:42,570 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:43:42,812 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:43:42,813 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:43:43,51 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:43:43,52 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
20:43:43,281 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
20:43:43,282 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
20:43:43,514 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
20:43:43,514 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:44:45,33 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:44:45,55 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:44:45,58 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:45:15,231 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:45:15,232 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:45:15,233 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:45:15,233 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:45:15,236 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:45:15,237 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:45:15,252 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:45:15,263 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:45:15,264 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:45:15,539 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:45:15,540 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:45:15,797 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:45:15,798 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:45:16,58 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:45:16,59 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:45:16,313 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:45:16,313 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:45:16,580 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:45:16,581 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:45:16,823 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:45:16,824 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:45:17,75 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:45:17,75 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:45:17,321 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:45:17,322 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:45:17,571 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:45:17,571 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:45:17,802 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:45:17,802 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:45:18,55 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:45:18,55 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:45:18,292 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:45:18,293 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
20:45:18,533 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
20:45:18,534 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
20:45:18,770 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
20:45:18,770 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:46:34,969 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:46:34,991 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:46:34,993 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:48:05,401 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:48:18,772 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:48:20,349 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:48:20,350 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:48:20,353 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:48:20,355 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:48:55,77 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:49:53,531 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:49:53,531 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:49:53,798 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:49:53,799 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:49:54,20 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:49:54,21 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:49:54,257 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:49:54,257 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:49:54,487 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:49:54,488 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:49:54,748 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:49:54,748 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:49:54,991 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:49:54,991 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:49:55,231 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:49:55,232 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:49:55,467 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:49:55,468 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:49:55,732 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:49:55,733 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:49:55,982 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:49:55,983 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:49:56,208 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:49:56,209 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:49:56,451 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:49:56,452 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
20:49:56,694 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
20:49:56,695 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
20:49:56,924 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
20:49:56,925 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:50:33,689 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:50:33,714 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:50:33,716 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:51:05,65 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:51:05,65 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:51:10,485 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:51:10,485 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:51:10,488 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:51:10,490 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:51:10,504 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:52:02,803 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:52:35,99 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:52:49,394 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:52:51,933 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:52:52,194 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:52:53,617 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:52:53,894 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:52:55,238 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:52:55,492 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:52:56,892 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:52:57,179 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:52:58,567 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:52:58,838 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:53:00,215 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:53:00,482 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:53:02,27 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:53:02,296 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:53:05,73 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:53:05,350 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:53:06,628 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:53:06,898 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:53:08,145 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:53:08,413 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:53:14,574 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:53:14,849 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:53:34,225 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
20:53:34,498 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
20:53:35,692 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
20:53:35,957 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
20:53:36,978 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:54:45,387 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:54:45,409 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:54:45,411 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:54:50,375 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:54:50,376 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:54:50,378 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:54:50,378 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:54:50,380 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:54:50,382 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:54:50,398 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:54:54,377 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:54:54,377 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:54:54,665 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:54:54,666 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:54:54,914 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:54:54,914 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:54:55,161 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:54:55,162 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:54:55,402 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:54:55,402 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:54:55,640 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:54:55,641 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:54:55,879 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:54:55,880 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:54:56,122 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:54:56,123 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:54:56,371 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:54:56,371 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:54:56,615 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:54:56,616 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:54:56,858 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:54:56,859 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:54:57,98 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:54:57,98 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:54:57,339 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:54:57,340 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
20:54:57,578 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
20:54:57,579 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
20:54:57,819 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
20:54:57,820 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:57:17,181 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:57:17,204 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:57:17,206 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:57:24,798 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:57:24,799 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:57:24,800 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:57:24,800 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:57:24,802 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:57:24,803 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:57:24,817 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:57:24,827 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:57:24,828 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:57:25,92 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:57:25,93 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:57:25,332 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:57:25,332 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:57:25,552 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:57:25,552 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:57:25,774 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:57:25,775 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:57:26,2 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:57:26,3 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:57:26,241 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:57:26,242 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:57:26,481 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:57:26,482 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:57:26,724 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:57:26,725 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:57:26,960 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:57:26,961 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:57:27,182 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:57:27,183 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:57:27,398 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:57:27,398 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:57:27,614 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:57:27,614 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
20:57:27,846 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
20:57:27,847 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
20:57:28,69 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
20:57:28,70 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:58:25,59 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:58:25,81 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:58:25,83 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
21:10:57,955 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
21:11:29,983 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:11:31,696 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
21:11:31,697 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
21:11:31,700 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:11:31,702 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:11:35,89 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
21:11:36,134 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:11:36,134 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
21:11:36,398 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
21:11:36,398 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
21:11:36,655 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
21:11:36,656 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
21:11:36,901 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
21:11:36,901 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
21:11:37,165 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
21:11:37,165 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
21:11:37,414 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
21:11:37,414 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
21:11:37,652 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
21:11:37,653 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
21:11:37,891 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
21:11:37,892 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
21:11:38,128 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
21:11:38,128 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
21:11:38,342 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
21:11:38,342 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
21:11:38,585 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
21:11:38,586 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
21:11:38,838 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
21:11:38,838 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
21:11:39,93 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
21:11:39,94 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
21:11:39,338 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
21:11:39,338 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
21:11:39,580 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
21:11:39,580 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
20:04:39,266 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:04:39,292 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:04:39,295 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:04:53,124 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:04:53,124 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:04:53,126 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:04:53,126 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:04:53,128 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:04:53,130 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:04:53,148 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:04:53,160 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:04:53,160 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:04:53,422 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:04:53,427 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:04:53,428 datashaper.workflow.workflow INFO executing verb orderby
20:04:53,433 datashaper.workflow.workflow INFO executing verb zip
20:04:53,436 datashaper.workflow.workflow INFO executing verb aggregate_override
20:04:53,443 datashaper.workflow.workflow INFO executing verb chunk
20:05:07,586 datashaper.workflow.workflow INFO executing verb select
20:05:07,592 datashaper.workflow.workflow INFO executing verb unroll
20:05:07,597 datashaper.workflow.workflow INFO executing verb rename
20:05:07,598 datashaper.workflow.workflow INFO executing verb genid
20:05:07,599 datashaper.workflow.workflow INFO executing verb unzip
20:05:07,601 datashaper.workflow.workflow INFO executing verb copy
20:05:07,602 datashaper.workflow.workflow INFO executing verb filter
20:05:07,619 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:07:49,843 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:07:49,864 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:07:49,866 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:07:49,871 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:07:49,871 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:07:49,872 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:07:49,872 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:07:49,873 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:07:49,873 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:07:49,880 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:07:49,884 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:07:49,884 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:07:50,124 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:07:50,124 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:07:50,125 datashaper.workflow.workflow INFO executing verb orderby
20:07:50,127 datashaper.workflow.workflow INFO executing verb zip
20:07:50,131 datashaper.workflow.workflow INFO executing verb aggregate_override
20:07:50,137 datashaper.workflow.workflow INFO executing verb chunk
20:07:50,826 datashaper.workflow.workflow INFO executing verb select
20:07:50,828 datashaper.workflow.workflow INFO executing verb unroll
20:07:50,832 datashaper.workflow.workflow INFO executing verb rename
20:07:50,833 datashaper.workflow.workflow INFO executing verb genid
20:07:50,834 datashaper.workflow.workflow INFO executing verb unzip
20:07:50,836 datashaper.workflow.workflow INFO executing verb copy
20:07:50,837 datashaper.workflow.workflow INFO executing verb filter
20:07:50,848 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:08:58,964 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:08:58,986 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:08:58,988 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:08:58,992 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:08:58,993 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:08:58,993 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:08:58,993 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:08:58,994 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:08:58,994 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:08:59,0 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:08:59,7 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:08:59,7 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:08:59,247 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:08:59,248 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:08:59,249 datashaper.workflow.workflow INFO executing verb orderby
20:08:59,251 datashaper.workflow.workflow INFO executing verb zip
20:08:59,253 datashaper.workflow.workflow INFO executing verb aggregate_override
20:08:59,260 datashaper.workflow.workflow INFO executing verb chunk
20:08:59,938 datashaper.workflow.workflow INFO executing verb select
20:08:59,940 datashaper.workflow.workflow INFO executing verb unroll
20:08:59,944 datashaper.workflow.workflow INFO executing verb rename
20:08:59,945 datashaper.workflow.workflow INFO executing verb genid
20:08:59,946 datashaper.workflow.workflow INFO executing verb unzip
20:08:59,948 datashaper.workflow.workflow INFO executing verb copy
20:08:59,949 datashaper.workflow.workflow INFO executing verb filter
20:08:59,960 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:15:21,753 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:15:21,779 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:15:21,782 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:15:21,786 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:15:21,786 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:15:21,787 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:15:21,787 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:15:21,788 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:15:21,788 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:15:21,795 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:15:21,799 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:15:21,799 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:15:22,29 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:15:22,30 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:15:22,31 datashaper.workflow.workflow INFO executing verb orderby
20:15:22,32 datashaper.workflow.workflow INFO executing verb zip
20:15:22,35 datashaper.workflow.workflow INFO executing verb aggregate_override
20:15:22,41 datashaper.workflow.workflow INFO executing verb chunk
20:15:22,714 datashaper.workflow.workflow INFO executing verb select
20:15:22,716 datashaper.workflow.workflow INFO executing verb unroll
20:15:22,720 datashaper.workflow.workflow INFO executing verb rename
20:15:22,721 datashaper.workflow.workflow INFO executing verb genid
20:15:22,723 datashaper.workflow.workflow INFO executing verb unzip
20:15:22,725 datashaper.workflow.workflow INFO executing verb copy
20:15:22,725 datashaper.workflow.workflow INFO executing verb filter
20:15:22,737 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:17:25,560 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:17:25,582 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:17:25,584 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:17:25,588 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:17:25,589 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:17:25,589 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:17:25,589 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:17:25,590 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:17:25,591 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:17:25,597 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:17:25,601 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:17:25,601 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:17:25,832 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:17:25,833 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:17:25,834 datashaper.workflow.workflow INFO executing verb orderby
20:17:25,836 datashaper.workflow.workflow INFO executing verb zip
20:17:25,840 datashaper.workflow.workflow INFO executing verb aggregate_override
20:17:25,846 datashaper.workflow.workflow INFO executing verb chunk
20:17:26,517 datashaper.workflow.workflow INFO executing verb select
20:17:26,519 datashaper.workflow.workflow INFO executing verb unroll
20:17:26,523 datashaper.workflow.workflow INFO executing verb rename
20:17:26,524 datashaper.workflow.workflow INFO executing verb genid
20:17:26,525 datashaper.workflow.workflow INFO executing verb unzip
20:17:26,527 datashaper.workflow.workflow INFO executing verb copy
20:17:26,528 datashaper.workflow.workflow INFO executing verb filter
20:17:26,540 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:20:31,565 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:20:31,586 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:20:31,589 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:20:31,593 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:20:31,593 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:20:31,594 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:20:31,594 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:20:31,595 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:20:31,595 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:20:31,602 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:20:31,606 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:20:31,606 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:20:31,845 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:20:31,846 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:20:31,847 datashaper.workflow.workflow INFO executing verb orderby
20:20:31,849 datashaper.workflow.workflow INFO executing verb zip
20:20:31,853 datashaper.workflow.workflow INFO executing verb aggregate_override
20:20:31,859 datashaper.workflow.workflow INFO executing verb chunk
20:20:32,533 datashaper.workflow.workflow INFO executing verb select
20:20:32,535 datashaper.workflow.workflow INFO executing verb unroll
20:20:32,538 datashaper.workflow.workflow INFO executing verb rename
20:20:32,539 datashaper.workflow.workflow INFO executing verb genid
20:20:32,541 datashaper.workflow.workflow INFO executing verb unzip
20:20:32,543 datashaper.workflow.workflow INFO executing verb copy
20:20:32,544 datashaper.workflow.workflow INFO executing verb filter
20:20:32,555 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:24:52,985 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:24:53,6 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:24:53,8 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:24:53,13 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:24:53,13 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:24:53,13 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:24:53,13 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:24:53,14 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:24:53,15 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:24:53,21 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:24:53,25 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:24:53,25 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:24:53,260 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:24:53,261 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:24:53,261 datashaper.workflow.workflow INFO executing verb orderby
20:24:53,263 datashaper.workflow.workflow INFO executing verb zip
20:24:53,267 datashaper.workflow.workflow INFO executing verb aggregate_override
20:24:53,273 datashaper.workflow.workflow INFO executing verb chunk
20:24:53,941 datashaper.workflow.workflow INFO executing verb select
20:24:53,943 datashaper.workflow.workflow INFO executing verb unroll
20:24:53,947 datashaper.workflow.workflow INFO executing verb rename
20:24:53,948 datashaper.workflow.workflow INFO executing verb genid
20:24:53,949 datashaper.workflow.workflow INFO executing verb unzip
20:24:53,952 datashaper.workflow.workflow INFO executing verb copy
20:24:53,952 datashaper.workflow.workflow INFO executing verb filter
20:24:53,964 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:32:28,612 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:32:28,633 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:32:28,636 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:32:28,640 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:32:28,640 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:32:28,641 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:32:28,641 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:32:28,642 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:32:28,642 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:32:28,649 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:32:28,655 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:32:28,655 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:32:28,892 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:32:28,892 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:32:28,893 datashaper.workflow.workflow INFO executing verb orderby
20:32:28,895 datashaper.workflow.workflow INFO executing verb zip
20:32:28,899 datashaper.workflow.workflow INFO executing verb aggregate_override
20:32:28,905 datashaper.workflow.workflow INFO executing verb chunk
20:32:29,573 datashaper.workflow.workflow INFO executing verb select
20:32:29,575 datashaper.workflow.workflow INFO executing verb unroll
20:32:29,579 datashaper.workflow.workflow INFO executing verb rename
20:32:29,580 datashaper.workflow.workflow INFO executing verb genid
20:32:29,582 datashaper.workflow.workflow INFO executing verb unzip
20:32:29,584 datashaper.workflow.workflow INFO executing verb copy
20:32:29,585 datashaper.workflow.workflow INFO executing verb filter
20:32:29,598 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:43:45,218 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:43:45,220 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
20:43:45,221 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
20:43:45,240 datashaper.workflow.workflow INFO executing verb entity_extract
20:43:45,247 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:43:45,266 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:43:45,267 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:43:49,674 datashaper.workflow.workflow INFO executing verb merge_graphs
20:43:49,880 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
20:47:32,788 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:47:32,812 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:47:32,814 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:47:32,820 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:47:32,821 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:47:32,821 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:47:32,821 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:47:32,822 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:47:32,823 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:47:32,829 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:47:32,837 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:47:32,837 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:47:33,106 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:47:33,107 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
20:47:33,108 datashaper.workflow.workflow INFO executing verb orderby
20:47:33,110 datashaper.workflow.workflow INFO executing verb zip
20:47:33,112 datashaper.workflow.workflow INFO executing verb aggregate_override
20:47:33,119 datashaper.workflow.workflow INFO executing verb chunk
20:47:33,831 datashaper.workflow.workflow INFO executing verb select
20:47:33,832 datashaper.workflow.workflow INFO executing verb unroll
20:47:33,836 datashaper.workflow.workflow INFO executing verb rename
20:47:33,837 datashaper.workflow.workflow INFO executing verb genid
20:47:33,839 datashaper.workflow.workflow INFO executing verb unzip
20:47:33,841 datashaper.workflow.workflow INFO executing verb copy
20:47:33,842 datashaper.workflow.workflow INFO executing verb filter
20:47:33,854 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
20:47:34,653 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:47:34,655 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
20:47:34,655 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
20:47:34,664 datashaper.workflow.workflow INFO executing verb entity_extract
20:47:34,670 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:47:34,690 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:47:34,690 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:47:36,290 datashaper.workflow.workflow INFO executing verb merge_graphs
20:47:36,628 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
20:51:02,524 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:51:02,527 assistant.memory.graphrag_v1.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities'].
20:51:02,527 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_extracted_entities.parquet.
20:51:02,536 datashaper.workflow.workflow INFO executing verb summarize_descriptions
20:51:02,826 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
19:56:29,51 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
19:56:29,74 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
19:56:29,77 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
19:56:29,128 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
19:56:29,129 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
19:56:29,129 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
19:56:29,129 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
19:56:29,130 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
19:56:29,131 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
19:56:29,142 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
19:56:29,147 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
19:56:29,148 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
19:56:29,527 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
19:56:29,528 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_text_units: [].
19:56:29,529 datashaper.workflow.workflow INFO executing verb orderby
19:56:29,534 datashaper.workflow.workflow INFO executing verb zip
19:56:29,541 datashaper.workflow.workflow INFO executing verb aggregate_override
19:56:29,554 datashaper.workflow.workflow INFO executing verb chunk
19:56:56,170 datashaper.workflow.workflow INFO executing verb select
19:56:56,177 datashaper.workflow.workflow INFO executing verb unroll
19:56:56,182 datashaper.workflow.workflow INFO executing verb rename
19:56:56,183 datashaper.workflow.workflow INFO executing verb genid
19:56:56,184 datashaper.workflow.workflow INFO executing verb unzip
19:56:56,186 datashaper.workflow.workflow INFO executing verb copy
19:56:56,187 datashaper.workflow.workflow INFO executing verb filter
19:56:56,203 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
19:56:57,517 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
19:56:57,518 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units'].
19:56:57,518 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
19:56:57,537 datashaper.workflow.workflow INFO executing verb entity_extract
19:56:57,545 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
19:56:57,564 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
19:56:57,564 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
19:56:58,774 datashaper.workflow.workflow INFO executing verb merge_graphs
19:56:58,952 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
19:57:02,86 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
19:57:02,86 assistant.memory.graphrag_v1.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities'].
19:57:02,87 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_extracted_entities.parquet.
19:57:02,92 datashaper.workflow.workflow INFO executing verb summarize_descriptions
19:57:02,337 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
20:42:41,770 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:42:41,772 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities'].
20:42:41,772 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_summarized_entities.parquet.
20:42:41,780 datashaper.workflow.workflow INFO executing verb cluster_graph
20:42:42,39 datashaper.workflow.workflow INFO executing verb select
20:42:42,47 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
20:18:35,916 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:18:35,940 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:18:35,942 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:18:35,996 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:18:35,997 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:18:35,998 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:18:35,998 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:18:36,0 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:18:36,1 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:18:36,16 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:18:36,28 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:18:36,29 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:18:36,306 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:18:36,306 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:18:36,576 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:18:36,576 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:18:36,826 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:18:36,827 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:18:37,98 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:18:37,99 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities'].
20:18:37,99 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_summarized_entities.parquet.
20:18:37,139 datashaper.workflow.workflow INFO executing verb cluster_graph
20:18:38,17 datashaper.workflow.workflow INFO executing verb select
20:18:38,21 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
20:19:05,251 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:19:05,252 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph'].
20:19:05,252 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:19:05,259 datashaper.workflow.workflow INFO executing verb unpack_graph
20:19:05,267 datashaper.workflow.workflow INFO executing verb rename
20:19:05,268 datashaper.workflow.workflow INFO executing verb select
20:19:05,269 datashaper.workflow.workflow INFO executing verb dedupe
20:19:05,271 datashaper.workflow.workflow INFO executing verb rename
20:19:05,273 datashaper.workflow.workflow INFO executing verb filter
20:19:05,288 datashaper.workflow.workflow INFO executing verb text_split
20:19:05,292 datashaper.workflow.workflow INFO executing verb drop
20:19:05,294 datashaper.workflow.workflow INFO executing verb merge
20:19:05,311 datashaper.workflow.workflow INFO executing verb text_embed
20:19:19,736 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:19:19,764 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0.
20:19:19,764 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25.
20:19:19,776 assistant.memory.graphrag_v1.index.verbs.text.embed.strategies.openai INFO embedding 26 inputs via 26 snippets using 2 batches. max_batch_size=16, max_tokens=8191
20:19:19,816 datashaper.workflow.workflow INFO executing verb drop
20:19:19,819 datashaper.workflow.workflow INFO executing verb filter
20:19:19,836 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
20:35:51,249 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:35:51,274 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:35:51,277 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:35:51,283 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:35:51,283 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:35:51,284 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:35:51,284 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:35:51,285 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:35:51,286 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:35:51,300 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:35:51,306 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:35:51,306 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:35:51,578 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:35:51,579 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:35:51,845 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:35:51,846 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:35:52,119 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:35:52,120 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:35:52,352 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:35:52,353 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:35:52,574 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:35:52,575 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph'].
20:35:52,575 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:35:52,589 datashaper.workflow.workflow INFO executing verb unpack_graph
20:35:52,598 datashaper.workflow.workflow INFO executing verb rename
20:35:52,599 datashaper.workflow.workflow INFO executing verb select
20:35:52,601 datashaper.workflow.workflow INFO executing verb dedupe
20:35:52,603 datashaper.workflow.workflow INFO executing verb rename
20:35:52,604 datashaper.workflow.workflow INFO executing verb filter
20:35:52,615 datashaper.workflow.workflow INFO executing verb text_split
20:35:52,619 datashaper.workflow.workflow INFO executing verb drop
20:35:52,620 datashaper.workflow.workflow INFO executing verb merge
20:35:52,639 datashaper.workflow.workflow INFO executing verb text_embed
20:35:53,352 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:35:53,369 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0.
20:35:53,369 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25.
20:35:53,375 assistant.memory.graphrag_v1.index.verbs.text.embed.strategies.openai INFO embedding 26 inputs via 26 snippets using 2 batches. max_batch_size=16, max_tokens=8191
20:35:53,396 datashaper.workflow.workflow INFO executing verb drop
20:35:53,397 datashaper.workflow.workflow INFO executing verb filter
20:35:53,407 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
20:40:38,341 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:40:38,363 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:40:38,366 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:40:38,370 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:40:38,370 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:40:38,371 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:40:38,371 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:40:38,372 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:40:38,372 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:40:38,381 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:40:38,388 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:40:38,389 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:40:38,717 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:40:38,718 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:40:39,25 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:40:39,25 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:40:39,273 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:40:39,274 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:40:39,513 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:40:39,514 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:40:39,759 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:40:39,759 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph'].
20:40:39,760 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:40:39,774 datashaper.workflow.workflow INFO executing verb unpack_graph
20:40:39,783 datashaper.workflow.workflow INFO executing verb rename
20:40:39,784 datashaper.workflow.workflow INFO executing verb select
20:40:39,786 datashaper.workflow.workflow INFO executing verb dedupe
20:40:39,787 datashaper.workflow.workflow INFO executing verb rename
20:40:39,788 datashaper.workflow.workflow INFO executing verb filter
20:40:39,798 datashaper.workflow.workflow INFO executing verb text_split
20:40:39,801 datashaper.workflow.workflow INFO executing verb drop
20:40:39,802 datashaper.workflow.workflow INFO executing verb merge
20:40:39,818 datashaper.workflow.workflow INFO executing verb text_embed
20:40:40,556 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:40:40,578 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0.
20:40:40,578 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25.
20:40:40,585 assistant.memory.graphrag_v1.index.verbs.text.embed.strategies.openai INFO embedding 26 inputs via 26 snippets using 2 batches. max_batch_size=16, max_tokens=8191
20:40:40,610 datashaper.workflow.workflow INFO executing verb drop
20:40:40,611 datashaper.workflow.workflow INFO executing verb filter
20:40:40,623 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
20:40:48,848 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:40:48,848 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph'].
20:40:48,849 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:40:48,855 datashaper.workflow.workflow INFO executing verb layout_graph
20:40:48,885 datashaper.workflow.workflow INFO executing verb unpack_graph
20:40:48,891 datashaper.workflow.workflow INFO executing verb unpack_graph
20:40:48,896 datashaper.workflow.workflow INFO executing verb filter
20:40:48,904 datashaper.workflow.workflow INFO executing verb drop
20:40:48,905 datashaper.workflow.workflow INFO executing verb select
20:40:48,906 datashaper.workflow.workflow INFO executing verb rename
20:40:48,908 datashaper.workflow.workflow INFO executing verb join
20:40:48,924 datashaper.workflow.workflow INFO executing verb convert
20:40:48,930 datashaper.workflow.workflow INFO executing verb rename
20:40:48,935 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
20:54:08,781 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:54:08,803 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:54:08,805 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:54:08,809 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:54:08,810 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:54:08,810 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:54:08,810 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:54:08,811 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:54:08,811 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:54:08,818 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:54:08,822 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:54:08,822 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:54:09,54 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:54:09,55 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:54:09,285 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:54:09,286 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:54:09,509 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:54:09,509 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:54:09,742 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:54:09,743 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:54:09,974 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:54:09,974 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:54:10,205 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:54:10,206 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph'].
20:54:10,206 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:54:10,219 datashaper.workflow.workflow INFO executing verb layout_graph
20:54:10,244 datashaper.workflow.workflow INFO executing verb unpack_graph
20:54:10,250 datashaper.workflow.workflow INFO executing verb unpack_graph
20:54:10,257 datashaper.workflow.workflow INFO executing verb drop
20:54:10,259 datashaper.workflow.workflow INFO executing verb filter
20:54:10,268 datashaper.workflow.workflow INFO executing verb select
20:54:10,269 datashaper.workflow.workflow INFO executing verb rename
20:54:10,270 datashaper.workflow.workflow INFO executing verb convert
20:54:10,276 datashaper.workflow.workflow INFO executing verb join
20:54:10,290 datashaper.workflow.workflow INFO executing verb rename
20:54:10,294 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
20:59:06,101 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:59:06,131 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:59:06,135 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:59:06,143 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:59:06,143 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:59:06,144 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:59:06,144 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:59:06,145 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:59:06,145 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:59:06,165 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:59:06,173 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:59:06,173 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:59:06,472 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:59:06,473 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:59:06,775 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:59:06,776 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:59:07,46 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:59:07,47 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:59:07,317 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:59:07,318 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:59:07,587 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:59:07,588 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:59:07,841 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:59:07,842 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph'].
20:59:07,842 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:59:07,856 datashaper.workflow.workflow INFO executing verb layout_graph
20:59:07,882 datashaper.workflow.workflow INFO executing verb unpack_graph
20:59:07,888 datashaper.workflow.workflow INFO executing verb unpack_graph
20:59:07,897 datashaper.workflow.workflow INFO executing verb filter
20:59:07,908 datashaper.workflow.workflow INFO executing verb drop
20:59:07,909 datashaper.workflow.workflow INFO executing verb select
20:59:07,911 datashaper.workflow.workflow INFO executing verb rename
20:59:07,912 datashaper.workflow.workflow INFO executing verb convert
20:59:07,919 datashaper.workflow.workflow INFO executing verb join
20:59:07,935 datashaper.workflow.workflow INFO executing verb rename
20:59:07,940 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
21:03:48,628 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
21:03:48,653 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:03:48,656 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
21:03:48,661 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
21:03:48,661 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:03:48,662 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
21:03:48,662 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
21:03:48,663 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:03:48,664 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:03:48,670 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
21:03:48,675 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:03:48,676 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
21:03:48,950 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
21:03:48,951 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
21:03:49,223 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
21:03:49,224 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
21:03:49,498 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
21:03:49,499 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
21:03:49,798 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
21:03:49,799 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
21:03:50,80 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
21:03:50,81 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
21:03:50,347 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
21:03:50,348 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph'].
21:03:50,348 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
21:03:50,363 datashaper.workflow.workflow INFO executing verb layout_graph
21:03:50,391 datashaper.workflow.workflow INFO executing verb unpack_graph
21:03:50,397 datashaper.workflow.workflow INFO executing verb unpack_graph
21:03:50,405 datashaper.workflow.workflow INFO executing verb filter
21:03:50,415 datashaper.workflow.workflow INFO executing verb drop
21:03:50,417 datashaper.workflow.workflow INFO executing verb select
21:03:50,418 datashaper.workflow.workflow INFO executing verb rename
21:03:50,419 datashaper.workflow.workflow INFO executing verb join
21:03:50,435 datashaper.workflow.workflow INFO executing verb convert
21:03:50,442 datashaper.workflow.workflow INFO executing verb rename
21:03:50,447 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
20:07:23,747 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:07:23,769 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:07:23,772 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:07:23,826 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:07:23,826 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:07:23,827 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:07:23,827 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:07:23,828 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:07:23,829 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:07:23,838 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:07:23,847 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:07:23,847 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:07:24,95 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:07:24,96 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:07:24,336 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:07:24,337 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:07:24,710 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:07:24,711 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:07:25,57 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:07:25,58 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:07:25,456 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:07:25,457 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:07:25,840 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:07:25,841 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:07:26,217 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:07:26,218 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph'].
20:07:26,219 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:07:26,271 datashaper.workflow.workflow INFO executing verb unpack_graph
20:07:26,286 datashaper.workflow.workflow INFO executing verb unpack_graph
20:07:26,296 datashaper.workflow.workflow INFO executing verb aggregate_override
20:07:26,315 datashaper.workflow.workflow INFO executing verb join
20:07:26,343 datashaper.workflow.workflow INFO executing verb join
20:07:26,359 datashaper.workflow.workflow INFO executing verb concat
20:07:26,362 datashaper.workflow.workflow INFO executing verb filter
20:07:26,387 datashaper.workflow.workflow INFO executing verb aggregate_override
20:07:26,400 datashaper.workflow.workflow INFO executing verb join
20:07:26,419 datashaper.workflow.workflow INFO executing verb filter
20:07:26,431 datashaper.workflow.workflow INFO executing verb fill
20:07:26,432 datashaper.workflow.workflow INFO executing verb merge
20:07:26,436 datashaper.workflow.workflow INFO executing verb copy
20:07:26,437 datashaper.workflow.workflow INFO executing verb select
20:07:26,442 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
20:07:21,75 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:07:21,97 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:07:21,100 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:07:21,152 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:07:21,153 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:07:21,153 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:07:21,153 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:07:21,155 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:07:21,155 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:07:21,164 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:07:21,172 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:07:21,172 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:07:21,437 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:07:21,438 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:07:21,682 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:07:21,682 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:07:21,915 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:07:21,916 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:07:22,158 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:07:22,159 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:07:22,400 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:07:22,401 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:07:22,792 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:07:22,793 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:07:23,197 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:07:23,198 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:07:23,584 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:07:23,584 assistant.memory.graphrag_v1.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities'].
20:07:23,586 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_entities.parquet.
20:07:23,635 datashaper.workflow.workflow INFO executing verb select
20:07:23,639 datashaper.workflow.workflow INFO executing verb unroll
20:07:23,646 datashaper.workflow.workflow INFO executing verb aggregate_override
20:07:23,660 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
20:10:15,448 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:10:15,450 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph'].
20:10:15,450 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:10:15,463 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
20:10:15,470 datashaper.workflow.workflow INFO executing verb unpack_graph
20:10:15,479 datashaper.workflow.workflow INFO executing verb filter
20:10:15,494 datashaper.workflow.workflow INFO executing verb rename
20:10:15,495 datashaper.workflow.workflow INFO executing verb filter
20:10:15,506 datashaper.workflow.workflow INFO executing verb drop
20:10:15,508 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
20:10:15,517 datashaper.workflow.workflow INFO executing verb convert
20:10:15,518 datashaper.workflow.workflow INFO executing verb convert
20:10:15,524 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
20:12:50,594 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:12:50,595 assistant.memory.graphrag_v1.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships'].
20:12:50,595 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:12:50,601 datashaper.workflow.workflow INFO executing verb select
20:12:50,603 datashaper.workflow.workflow INFO executing verb unroll
20:12:50,607 datashaper.workflow.workflow INFO executing verb aggregate_override
20:12:50,611 datashaper.workflow.workflow INFO executing verb select
20:12:50,615 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
20:15:29,68 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:15:29,68 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
20:15:29,69 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:15:29,75 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:15:29,81 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:15:29,85 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:15:29,88 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:15:29,97 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:15:29,99 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:15:37,844 datashaper.workflow.workflow INFO executing verb create_community_reports
20:15:37,855 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:15:37,873 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:15:37,873 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:15:37,892 datashaper.workflow.workflow INFO executing verb window
20:15:37,897 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:18:07,874 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:18:07,896 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:18:07,898 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:18:07,902 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:18:07,903 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:18:07,903 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:18:07,903 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:18:07,904 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:18:07,904 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:18:07,911 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:18:07,917 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:18:07,917 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:18:08,156 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:18:08,157 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:18:08,392 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:18:08,393 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:18:08,627 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:18:08,628 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:18:08,861 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:18:08,862 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:18:09,85 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:18:09,85 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:18:09,297 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:18:09,297 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:18:09,523 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:18:09,523 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:18:09,757 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:18:09,758 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:18:09,990 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:18:09,991 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:18:10,211 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:18:10,211 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:18:10,445 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:18:10,445 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:18:10,679 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:18:10,680 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids', 'create_base_text_units'].
20:18:10,681 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_entity_ids.parquet.
20:18:10,693 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_relationship_ids.parquet.
20:18:10,698 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
20:18:10,704 datashaper.workflow.workflow INFO executing verb select
20:18:10,706 datashaper.workflow.workflow INFO executing verb rename
20:18:10,707 datashaper.workflow.workflow INFO executing verb join
20:18:10,723 datashaper.workflow.workflow INFO executing verb join
20:18:10,735 datashaper.workflow.workflow INFO executing verb aggregate_override
20:18:10,741 datashaper.workflow.workflow INFO executing verb select
20:18:10,745 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
20:19:51,426 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:19:51,451 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:19:51,453 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:19:51,457 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:19:51,458 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:19:51,458 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:19:51,458 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:19:51,459 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:19:51,460 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:19:51,466 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:19:51,472 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:19:51,472 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:19:51,739 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:19:51,740 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:19:51,973 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:19:51,974 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:19:52,243 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:19:52,243 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:19:52,463 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:19:52,464 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:19:52,692 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:19:52,693 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:19:52,936 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:19:52,936 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:19:53,181 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:19:53,181 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:19:53,413 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:19:53,414 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:19:53,645 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:19:53,646 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:19:53,891 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:19:53,892 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:19:54,155 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:19:54,156 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
20:19:54,156 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:19:54,173 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:19:54,180 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:19:54,186 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:19:54,191 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:19:54,204 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:19:54,205 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:19:54,945 datashaper.workflow.workflow INFO executing verb create_community_reports
20:19:54,953 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:19:54,970 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:19:54,970 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:19:54,989 datashaper.workflow.workflow INFO executing verb window
20:19:54,994 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:25:00,308 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:25:00,330 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:25:00,332 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:25:00,337 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:25:00,337 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:25:00,337 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:25:00,338 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:25:00,338 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:25:00,339 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:25:00,345 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:25:00,351 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:25:00,351 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:25:00,572 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:25:00,573 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:25:00,803 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:25:00,803 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:25:01,31 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:25:01,31 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:25:01,243 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:25:01,244 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:25:01,457 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:25:01,457 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:25:01,671 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:25:01,672 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:25:01,906 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:25:01,907 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:25:02,123 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:25:02,123 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:25:02,340 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:25:02,341 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:25:02,551 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:25:02,552 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:25:02,776 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:25:02,776 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
20:25:02,777 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:25:02,791 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:25:02,797 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:25:02,803 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:25:02,807 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:25:02,817 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:25:02,818 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:25:03,557 datashaper.workflow.workflow INFO executing verb create_community_reports
20:25:03,564 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:25:03,581 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:25:03,582 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:25:03,601 datashaper.workflow.workflow INFO executing verb window
20:25:03,605 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:35:01,101 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:35:01,123 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:35:01,125 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:35:01,130 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:35:01,130 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:35:01,130 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:35:01,130 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:35:01,131 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:35:01,132 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:35:01,138 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:35:01,142 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:35:01,143 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:35:01,423 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:35:01,423 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:35:01,669 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:35:01,669 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:35:01,907 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:35:01,908 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:35:02,173 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:35:02,174 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:35:02,420 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:35:02,421 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:35:02,661 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:35:02,661 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:35:02,901 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:35:02,902 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:35:03,136 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:35:03,137 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:35:03,372 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:35:03,373 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:35:03,611 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:35:03,612 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:35:03,846 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:35:03,847 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes'].
20:35:03,847 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:35:03,861 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:35:03,868 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:35:03,873 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:35:03,877 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:35:03,887 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:35:03,888 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:35:04,613 datashaper.workflow.workflow INFO executing verb create_community_reports
20:35:04,621 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:35:04,638 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:35:04,638 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:35:04,658 datashaper.workflow.workflow INFO executing verb window
20:35:04,661 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:37:06,425 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:37:06,447 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:37:06,449 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:37:06,454 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:37:06,454 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:37:06,454 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:37:06,454 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:37:06,455 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:37:06,456 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:37:06,461 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:37:06,465 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:37:06,465 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:37:06,714 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:37:06,715 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:37:06,954 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:37:06,954 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:37:07,202 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:37:07,203 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:37:07,438 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:37:07,439 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:37:07,675 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:37:07,676 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:37:07,938 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:37:07,939 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:37:08,172 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:37:08,172 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:37:08,387 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:37:08,388 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:37:08,610 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:37:08,611 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:37:08,871 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:37:08,872 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:37:09,167 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:37:09,167 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes'].
20:37:09,168 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:37:09,183 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:37:09,191 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:37:09,197 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:37:09,202 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:37:09,213 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:37:09,214 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:37:10,50 datashaper.workflow.workflow INFO executing verb create_community_reports
20:37:10,60 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:37:10,81 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:37:10,81 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:37:10,102 datashaper.workflow.workflow INFO executing verb window
20:37:10,108 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:38:38,21 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:38:38,43 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:38:38,46 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:38:38,50 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:38:38,50 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:38:38,51 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:38:38,51 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:38:38,52 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:38:38,52 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:38:38,59 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:38:38,64 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:38:38,64 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:38:38,308 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:38:38,308 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:38:38,546 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:38:38,547 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:38:38,781 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:38:38,782 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:38:38,993 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:38:38,994 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:38:39,205 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:38:39,206 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:38:39,435 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:38:39,436 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:38:39,668 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:38:39,668 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:38:39,902 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:38:39,903 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:38:40,136 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:38:40,137 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:38:40,370 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:38:40,371 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:38:40,605 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:38:40,606 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
20:38:40,606 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:38:40,621 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:38:40,626 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:38:40,632 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:38:40,636 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:38:40,646 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:38:40,647 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:38:41,367 datashaper.workflow.workflow INFO executing verb create_community_reports
20:38:41,375 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:38:41,392 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:38:41,392 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:38:41,411 datashaper.workflow.workflow INFO executing verb window
20:38:41,414 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:45:25,39 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:45:25,61 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:45:25,63 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:45:25,68 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:45:25,68 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:45:25,68 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:45:25,69 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:45:25,69 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:45:25,70 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:45:25,76 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:45:25,83 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:45:25,83 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:45:25,332 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:45:25,333 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:45:25,568 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:45:25,569 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:45:25,806 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:45:25,807 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:45:26,44 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:45:26,45 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:45:26,278 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:45:26,278 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:45:26,497 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:45:26,498 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:45:26,735 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:45:26,736 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:45:26,984 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:45:26,984 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:45:27,217 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:45:27,218 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:45:27,470 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:45:27,471 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:45:27,708 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:45:27,709 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes'].
20:45:27,710 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:45:27,725 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:45:27,732 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:45:27,737 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:45:27,741 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:45:27,751 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:45:27,752 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:45:28,497 datashaper.workflow.workflow INFO executing verb create_community_reports
20:45:28,505 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:45:28,522 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:45:28,522 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:45:28,542 datashaper.workflow.workflow INFO executing verb window
20:45:28,546 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:50:33,526 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:50:33,551 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:50:33,554 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:50:33,562 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:50:33,562 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:50:33,563 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:50:33,563 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:50:33,565 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:50:33,566 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:50:33,576 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:50:33,583 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:50:33,583 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:50:33,837 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:50:33,838 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:50:34,75 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:50:34,75 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:50:34,311 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:50:34,312 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:50:34,549 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:50:34,550 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:50:34,789 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:50:34,790 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:50:35,62 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:50:35,63 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:50:35,342 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:50:35,343 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:50:35,631 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:50:35,632 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:50:35,905 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:50:35,906 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:50:36,165 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:50:36,165 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:50:36,431 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:50:36,432 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
20:50:36,432 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:50:36,448 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:50:36,458 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:50:36,464 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:50:36,468 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:50:36,480 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:50:36,481 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:50:37,288 datashaper.workflow.workflow INFO executing verb create_community_reports
20:50:37,296 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:50:37,314 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:50:37,314 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:50:37,334 datashaper.workflow.workflow INFO executing verb window
20:50:37,338 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:52:53,461 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:52:53,462 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids'].
20:52:53,462 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
20:52:53,468 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_relationship_ids.parquet.
20:52:53,472 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_entity_ids.parquet.
20:52:53,477 datashaper.workflow.workflow INFO executing verb select
20:52:53,478 datashaper.workflow.workflow INFO executing verb rename
20:52:53,479 datashaper.workflow.workflow INFO executing verb join
20:52:53,494 datashaper.workflow.workflow INFO executing verb join
20:52:53,507 datashaper.workflow.workflow INFO executing verb aggregate_override
20:52:53,512 datashaper.workflow.workflow INFO executing verb select
20:52:53,516 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
20:54:31,906 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:54:31,927 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:54:31,929 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:54:31,934 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:54:31,934 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:54:31,934 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:54:31,934 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:54:31,935 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:54:31,936 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:54:31,942 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:54:31,949 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:54:31,949 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:54:32,194 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:54:32,194 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:54:32,431 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:54:32,432 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:54:32,644 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:54:32,645 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:54:32,871 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:54:32,872 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:54:33,94 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:54:33,95 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:54:33,327 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:54:33,328 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:54:33,561 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:54:33,562 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:54:33,797 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:54:33,797 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:54:34,31 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:54:34,32 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:54:34,277 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:54:34,278 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:54:34,507 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:54:34,507 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
20:54:34,725 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:54:34,726 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids', 'create_base_text_units'].
20:54:34,726 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_relationship_ids.parquet.
20:54:34,738 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_entity_ids.parquet.
20:54:34,742 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
20:54:34,747 datashaper.workflow.workflow INFO executing verb select
20:54:34,749 datashaper.workflow.workflow INFO executing verb rename
20:54:34,750 datashaper.workflow.workflow INFO executing verb join
20:54:34,766 datashaper.workflow.workflow INFO executing verb join
20:54:34,778 datashaper.workflow.workflow INFO executing verb aggregate_override
20:54:34,784 datashaper.workflow.workflow INFO executing verb select
20:54:34,787 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
20:57:42,900 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
20:57:42,922 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
20:57:42,924 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
20:57:42,929 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
20:57:42,929 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
20:57:42,930 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
20:57:42,930 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
20:57:42,930 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
20:57:42,931 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
20:57:42,937 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
20:57:42,941 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
20:57:42,942 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
20:57:43,187 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
20:57:43,188 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
20:57:43,426 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
20:57:43,426 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
20:57:43,705 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
20:57:43,706 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
20:57:43,944 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
20:57:43,945 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
20:57:44,165 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
20:57:44,166 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
20:57:44,377 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
20:57:44,377 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
20:57:44,590 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
20:57:44,590 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
20:57:44,822 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
20:57:44,822 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
20:57:45,66 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
20:57:45,67 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
20:57:45,335 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
20:57:45,336 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
20:57:45,583 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
20:57:45,584 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships'].
20:57:45,584 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_nodes.parquet.
20:57:45,607 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_relationships.parquet.
20:57:45,638 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
20:57:45,646 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
20:57:45,655 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
20:57:45,670 datashaper.workflow.workflow INFO executing verb prepare_community_reports
20:57:45,671 assistant.memory.graphrag_v1.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 26.
20:57:46,467 datashaper.workflow.workflow INFO executing verb create_community_reports
20:57:46,475 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
20:57:46,491 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0.
20:57:46,492 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25.
20:57:46,511 datashaper.workflow.workflow INFO executing verb window
20:57:46,515 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
20:57:54,991 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
20:57:54,992 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_relationship_ids'].
20:57:54,993 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_entity_ids.parquet.
20:57:54,998 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
20:57:55,3 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_relationship_ids.parquet.
20:57:55,7 datashaper.workflow.workflow INFO executing verb select
20:57:55,9 datashaper.workflow.workflow INFO executing verb rename
20:57:55,10 datashaper.workflow.workflow INFO executing verb join
20:57:55,24 datashaper.workflow.workflow INFO executing verb join
20:57:55,37 datashaper.workflow.workflow INFO executing verb aggregate_override
20:57:55,42 datashaper.workflow.workflow INFO executing verb select
20:57:55,46 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
21:01:45,607 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
21:01:45,630 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:01:45,632 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
21:01:45,637 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
21:01:45,637 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:01:45,638 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
21:01:45,638 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
21:01:45,639 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:01:45,639 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:01:45,646 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
21:01:45,654 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:01:45,654 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
21:01:45,909 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
21:01:45,910 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
21:01:46,130 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
21:01:46,130 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
21:01:46,348 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
21:01:46,349 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
21:01:46,581 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
21:01:46,582 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
21:01:46,822 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
21:01:46,822 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
21:01:47,65 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
21:01:47,66 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
21:01:47,308 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
21:01:47,308 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
21:01:47,546 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
21:01:47,547 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
21:01:47,788 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
21:01:47,788 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
21:01:48,4 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
21:01:48,5 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
21:01:48,223 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
21:01:48,223 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
21:01:48,471 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
21:01:48,471 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids', 'create_base_text_units'].
21:01:48,472 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_entity_ids.parquet.
21:01:48,483 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_relationship_ids.parquet.
21:01:48,487 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
21:01:48,493 datashaper.workflow.workflow INFO executing verb select
21:01:48,495 datashaper.workflow.workflow INFO executing verb rename
21:01:48,496 datashaper.workflow.workflow INFO executing verb join
21:01:48,512 datashaper.workflow.workflow INFO executing verb join
21:01:48,524 datashaper.workflow.workflow INFO executing verb aggregate_override
21:01:48,531 datashaper.workflow.workflow INFO executing verb select
21:01:48,535 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
21:03:36,180 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
21:03:36,181 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_documents: ['create_final_text_units'].
21:03:36,181 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_text_units.parquet.
21:03:36,187 datashaper.workflow.workflow INFO executing verb unroll
21:03:36,192 datashaper.workflow.workflow INFO executing verb select
21:03:36,193 datashaper.workflow.workflow INFO executing verb rename
21:03:36,194 datashaper.workflow.workflow INFO executing verb join
21:03:36,207 datashaper.workflow.workflow INFO executing verb aggregate_override
21:03:36,212 datashaper.workflow.workflow INFO executing verb join
21:03:36,226 datashaper.workflow.workflow INFO executing verb rename
21:03:36,227 datashaper.workflow.workflow INFO executing verb convert
21:03:36,236 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
21:08:43,297 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
21:08:43,321 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:08:43,323 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
21:08:43,327 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
21:08:43,328 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:08:43,328 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
21:08:43,328 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
21:08:43,329 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:08:43,330 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:08:43,335 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
21:08:43,340 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:08:43,340 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
21:08:43,621 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
21:08:43,621 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
21:08:43,847 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
21:08:43,847 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
21:08:44,90 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
21:08:44,90 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
21:08:44,340 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
21:08:44,340 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
21:08:44,582 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
21:08:44,582 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
21:08:44,817 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
21:08:44,818 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
21:08:45,53 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
21:08:45,53 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
21:08:45,330 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
21:08:45,330 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
21:08:45,582 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
21:08:45,582 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
21:08:45,827 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
21:08:45,828 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
21:08:46,91 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
21:08:46,91 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
21:08:46,326 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
21:08:46,327 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
21:08:46,578 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
21:08:46,579 assistant.memory.graphrag_v1.index.run INFO dependencies for create_base_documents: ['create_final_text_units'].
21:08:46,579 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_final_text_units.parquet.
21:08:46,594 datashaper.workflow.workflow INFO executing verb unroll
21:08:46,600 datashaper.workflow.workflow INFO executing verb select
21:08:46,601 datashaper.workflow.workflow INFO executing verb rename
21:08:46,602 datashaper.workflow.workflow INFO executing verb join
21:08:46,616 datashaper.workflow.workflow INFO executing verb aggregate_override
21:08:46,622 datashaper.workflow.workflow INFO executing verb join
21:08:46,634 datashaper.workflow.workflow INFO executing verb rename
21:08:46,635 datashaper.workflow.workflow INFO executing verb convert
21:08:46,643 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
21:09:07,281 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
21:09:07,283 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_documents: ['create_base_documents'].
21:09:07,284 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_documents.parquet.
21:09:07,292 datashaper.workflow.workflow INFO executing verb rename
21:09:07,298 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
21:11:22,439 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
21:11:22,460 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:11:22,462 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
21:11:22,467 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
21:11:22,467 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:11:22,467 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
21:11:22,468 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
21:11:22,468 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:11:22,469 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:11:22,475 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
21:11:22,482 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:11:22,483 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
21:11:22,712 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
21:11:22,712 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
21:11:22,943 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
21:11:22,944 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
21:11:23,181 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
21:11:23,181 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
21:11:23,418 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
21:11:23,419 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
21:11:23,654 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
21:11:23,654 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_entities because it already exists.
21:11:23,897 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
21:11:23,898 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
21:11:24,141 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
21:11:24,142 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
21:11:24,385 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
21:11:24,385 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
21:11:24,611 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
21:11:24,612 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
21:11:24,828 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
21:11:24,829 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
21:11:25,62 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
21:11:25,63 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
21:11:25,297 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
21:11:25,298 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_relationship_ids'].
21:11:25,298 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_entity_ids.parquet.
21:11:25,310 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_text_units.parquet.
21:11:25,315 assistant.memory.graphrag_v1.index.run INFO read table form storage: join_text_units_to_relationship_ids.parquet.
21:11:25,320 datashaper.workflow.workflow INFO executing verb select
21:11:25,322 datashaper.workflow.workflow INFO executing verb rename
21:11:25,323 datashaper.workflow.workflow INFO executing verb join
21:11:25,338 datashaper.workflow.workflow INFO executing verb join
21:11:25,350 datashaper.workflow.workflow INFO executing verb aggregate_override
21:11:25,356 datashaper.workflow.workflow INFO executing verb select
21:11:25,360 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
21:11:35,432 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
21:11:35,433 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
21:11:35,675 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
21:11:35,676 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
21:09:04,843 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
21:09:04,865 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:09:04,867 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
21:09:04,922 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
21:09:04,922 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:09:04,922 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
21:09:04,922 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
21:09:04,924 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:09:04,924 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:09:04,931 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
21:09:04,935 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:09:04,935 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
21:09:05,164 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
21:09:05,164 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
21:09:05,378 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
21:09:05,379 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
21:09:05,596 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
21:09:05,596 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
21:09:05,805 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
21:09:05,805 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
21:09:06,11 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
21:09:06,12 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph'].
21:09:06,12 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
21:09:06,28 datashaper.workflow.workflow INFO executing verb unpack_graph
21:09:06,35 datashaper.workflow.workflow INFO executing verb rename
21:09:06,36 datashaper.workflow.workflow INFO executing verb select
21:09:06,38 datashaper.workflow.workflow INFO executing verb dedupe
21:09:06,39 datashaper.workflow.workflow INFO executing verb rename
21:09:06,40 datashaper.workflow.workflow INFO executing verb filter
21:09:06,55 datashaper.workflow.workflow INFO executing verb text_split
21:09:06,58 datashaper.workflow.workflow INFO executing verb drop
21:09:06,59 datashaper.workflow.workflow INFO executing verb merge
21:16:46,262 assistant.memory.graphrag_v1.config.read_dotenv INFO Loading pipeline .env file
21:16:46,284 assistant.memory.graphrag_v1.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "concurent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "loca_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:16:46,286 assistant.memory.graphrag_v1.index.create_pipeline_config INFO Skipping workflows 
21:16:46,291 assistant.memory.graphrag_v1.index.run INFO Running pipeline.
21:16:46,291 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO Creating file storage at ragtest/output/20241004-165816/artifacts
21:16:46,292 assistant.memory.graphrag_v1.index.input.load_input INFO loading input from root_dir=input
21:16:46,292 assistant.memory.graphrag_v1.index.input.load_input INFO using file storage for input.
21:16:46,293 assistant.memory.graphrag_v1.index.storage.file_pipline_storage INFO search ragtest/input for files matching .*\.txt$
21:16:46,293 assistant.memory.graphrag_v1.index.input.text INFO Found text files from input, found [('book.txt', {})].
21:16:46,298 assistant.memory.graphrag_v1.index.input.text INFO Found 1 files, loading 1
21:16:46,303 assistant.memory.graphrag_v1.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents'].
21:16:46,303 assistant.memory.graphrag_v1.index.run INFO Final # of rows loaded: 1.
21:16:46,551 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_text_units...
21:16:46,551 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_text_units because it already exists.
21:16:46,789 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_extracted_entities...
21:16:46,790 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_extracted_entities because it already exists.
21:16:47,37 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_summarized_entities...
21:16:47,38 assistant.memory.graphrag_v1.index.run INFO Skipping create_summarized_entities because it already exists.
21:16:47,288 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_entity_graph...
21:16:47,289 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_entity_graph because it already exists.
21:16:47,543 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_entities...
21:16:47,544 assistant.memory.graphrag_v1.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph'].
21:16:47,544 assistant.memory.graphrag_v1.index.run INFO read table form storage: create_base_entity_graph.parquet.
21:16:47,558 datashaper.workflow.workflow INFO executing verb unpack_graph
21:16:47,565 datashaper.workflow.workflow INFO executing verb rename
21:16:47,566 datashaper.workflow.workflow INFO executing verb select
21:16:47,568 datashaper.workflow.workflow INFO executing verb dedupe
21:16:47,569 datashaper.workflow.workflow INFO executing verb rename
21:16:47,570 datashaper.workflow.workflow INFO executing verb filter
21:16:47,579 datashaper.workflow.workflow INFO executing verb text_split
21:16:47,583 datashaper.workflow.workflow INFO executing verb drop
21:16:47,584 datashaper.workflow.workflow INFO executing verb merge
21:16:47,599 datashaper.workflow.workflow INFO executing verb text_embed
21:17:39,110 assistant.memory.graphrag_v1.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
21:17:39,128 assistant.memory.graphrag_v1.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0.
21:17:39,128 assistant.memory.graphrag_v1.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25.
21:17:39,134 assistant.memory.graphrag_v1.index.verbs.text.embed.strategies.openai INFO embedding 26 inputs via 26 snippets using 2 batches. max_batch_size=16, max_tokens=8191
21:17:39,157 datashaper.workflow.workflow INFO executing verb drop
21:17:39,158 datashaper.workflow.workflow INFO executing verb filter
21:17:39,168 assistant.memory.graphrag_v1.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
21:17:39,435 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_nodes...
21:17:39,436 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_nodes because it already exists.
21:17:39,667 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_communities...
21:17:39,668 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_communities because it already exists.
21:17:39,903 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_entity_ids...
21:17:39,904 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_entity_ids because it already exists.
21:17:40,138 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_relationships...
21:17:40,139 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_relationships because it already exists.
21:17:40,372 assistant.memory.graphrag_v1.index.run INFO Running workflow: join_text_units_to_relationship_ids...
21:17:40,373 assistant.memory.graphrag_v1.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists.
21:17:40,625 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_community_reports...
21:17:40,626 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_community_reports because it already exists.
21:17:40,848 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_text_units...
21:17:40,849 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_text_units because it already exists.
21:17:41,57 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_base_documents...
21:17:41,57 assistant.memory.graphrag_v1.index.run INFO Skipping create_base_documents because it already exists.
21:17:41,279 assistant.memory.graphrag_v1.index.run INFO Running workflow: create_final_documents...
21:17:41,280 assistant.memory.graphrag_v1.index.run INFO Skipping create_final_documents because it already exists.
